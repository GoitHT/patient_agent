# å°†å¢å¼ºç‰ˆ RAG æ•´åˆåˆ° patient_agent é¡¹ç›®

## ğŸ“‹ æ•´åˆæ­¥éª¤

### 1. æ›´æ–°ä¾èµ–

åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `requirements.txt` ä¸­æ·»åŠ ï¼š

```txt
# RAG å¢å¼ºåŠŸèƒ½
rank-bm25>=0.2.2
jieba>=0.42.1
```

ç„¶åå®‰è£…ï¼š
```bash
pip install rank-bm25 jieba
```

### 2. æ›¿æ¢ç°æœ‰ RAG æ¨¡å—

#### æ–¹å¼ Aï¼šå®Œå…¨æ›¿æ¢ï¼ˆæ¨èï¼‰

åœ¨ `src/config.yaml` ä¸­é…ç½®ï¼š

```yaml
rag:
  retriever_type: "enhanced"  # ä½¿ç”¨å¢å¼ºç‰ˆ
  spllm_root: "./SPLLM-RAG1"
  enable_hybrid: true
  enable_hierarchical: true
  cosine_threshold: 0.3
```

åœ¨ `src/rag.py` ä¸­ä¿®æ”¹ï¼š

```python
# åŸæ¥çš„å¯¼å…¥
# from src.rag.adaptive_rag_retriever import AdaptiveRAGRetriever

# æ”¹ä¸º
from src.rag.enhanced_rag_retriever import EnhancedRAGRetriever

# åˆå§‹åŒ–æ—¶
def init_rag_retriever(config):
    """åˆå§‹åŒ– RAG æ£€ç´¢å™¨"""
    return EnhancedRAGRetriever(
        spllm_root=config.get("spllm_root", "./SPLLM-RAG1"),
        enable_hybrid=config.get("enable_hybrid", True),
        enable_rerank=config.get("enable_rerank", False),
        cosine_threshold=config.get("cosine_threshold", 0.3),
    )
```

#### æ–¹å¼ Bï¼šå…¼å®¹æ¨¡å¼ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰

æ·»åŠ é…ç½®å¼€å…³ï¼Œæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š

```python
def init_rag_retriever(config):
    """åˆå§‹åŒ– RAG æ£€ç´¢å™¨ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰"""
    retriever_type = config.get("retriever_type", "adaptive")
    
    if retriever_type == "enhanced":
        from src.rag.enhanced_rag_retriever import EnhancedRAGRetriever
        return EnhancedRAGRetriever(
            spllm_root=config["spllm_root"],
            enable_hybrid=config.get("enable_hybrid", True),
        )
    else:
        from src.rag.adaptive_rag_retriever import AdaptiveRAGRetriever
        return AdaptiveRAGRetriever(
            spllm_root=config["spllm_root"],
        )
```

### 3. æ•´åˆåˆ°åŒ»ç”Ÿæ™ºèƒ½ä½“

åœ¨ `src/agents/doctor_agent.py` ä¸­ä½¿ç”¨ï¼š

```python
class DoctorAgent:
    def __init__(self, rag_retriever, llm_client):
        self.rag = rag_retriever
        self.llm = llm_client
    
    def diagnose(self, patient_symptoms, patient_id=None):
        """è¯Šæ–­æ‚£è€…"""
        # 1. æ£€ç´¢ç›¸å…³åŒ»å­¦çŸ¥è¯†
        query = f"æ‚£è€…ç—‡çŠ¶ï¼š{patient_symptoms}"
        
        results = self.rag.retrieve(
            query=query,
            filters={"patient_id": patient_id} if patient_id else None,
            k=5,
            enable_hierarchical=True  # å¯ç”¨åˆ†å±‚æ£€ç´¢
        )
        
        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([
            f"å‚è€ƒèµ„æ–™ {i+1} (æ¥æº: {r['meta']['source']}):\n{r['text']}"
            for i, r in enumerate(results)
        ])
        
        # 3. ç”Ÿæˆè¯Šæ–­
        prompt = f"""
åŸºäºä»¥ä¸‹åŒ»å­¦çŸ¥è¯†ï¼Œè¯Šæ–­æ‚£è€…ç—…æƒ…ï¼š

{context}

æ‚£è€…ç—‡çŠ¶ï¼š
{patient_symptoms}

è¯·ç»™å‡ºè¯Šæ–­å»ºè®®ï¼š
"""
        
        diagnosis = self.llm.generate(prompt)
        
        return {
            "diagnosis": diagnosis,
            "reference_sources": [r['meta']['source'] for r in results],
            "confidence": self._calculate_confidence(results)
        }
    
    def _calculate_confidence(self, results):
        """æ ¹æ®æ£€ç´¢ç»“æœè®¡ç®—è¯Šæ–­ç½®ä¿¡åº¦"""
        if not results:
            return 0.0
        
        # åŸºäºæ£€ç´¢åˆ†æ•°è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_score = sum(r['score'] for r in results) / len(results)
        return min(1.0, avg_score)
```

### 4. å®ç°å¯¹è¯åçš„çŸ¥è¯†åº“æ›´æ–°

åœ¨å¯¹è¯æµç¨‹ç»“æŸåï¼Œæ›´æ–°çŸ¥è¯†åº“ï¼š

```python
class DialogueManager:
    def __init__(self, rag_retriever):
        self.rag = rag_retriever
    
    def end_dialogue(self, patient_id, dialogue_history, diagnosis, treatment):
        """å¯¹è¯ç»“æŸæ—¶çš„å¤„ç†"""
        
        # 1. ç”Ÿæˆå¯¹è¯æ‘˜è¦
        summary = self._generate_summary(dialogue_history)
        
        # 2. æ›´æ–°æ‚£è€…å†å²
        self.rag.update_history(
            patient_id=patient_id,
            dialogue_summary=summary,
            diagnosis=diagnosis,
            treatment=treatment
        )
        
        # 3. æå–é«˜è´¨é‡é—®ç­”å¯¹
        qa_pairs = self._extract_qa_pairs(dialogue_history)
        
        for qa in qa_pairs:
            quality_score = self._evaluate_quality(qa)
            
            if quality_score > 0.7:
                self.rag.update_high_quality_qa(
                    question=qa['question'],
                    answer=qa['answer'],
                    quality_score=quality_score
                )
    
    def _generate_summary(self, dialogue_history):
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        # ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        dialogue_text = "\n".join([
            f"{msg['role']}: {msg['content']}"
            for msg in dialogue_history
        ])
        
        summary_prompt = f"""
è¯·æ€»ç»“ä»¥ä¸‹åŒ»æ‚£å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼š

{dialogue_text}

è¦æ±‚ï¼š
1. æå–ä¸»è¦ç—‡çŠ¶
2. è¯Šæ–­ç»“æœ
3. æ²»ç–—æ–¹æ¡ˆ
4. æ‚£è€…å…³æ³¨ç‚¹
"""
        
        return self.llm.generate(summary_prompt)
    
    def _extract_qa_pairs(self, dialogue_history):
        """ä»å¯¹è¯ä¸­æå–é—®ç­”å¯¹"""
        qa_pairs = []
        
        for i in range(len(dialogue_history) - 1):
            if dialogue_history[i]['role'] == 'patient':
                question = dialogue_history[i]['content']
                
                # æ‰¾åˆ°åŒ»ç”Ÿçš„å›ç­”
                for j in range(i + 1, len(dialogue_history)):
                    if dialogue_history[j]['role'] == 'doctor':
                        answer = dialogue_history[j]['content']
                        qa_pairs.append({
                            'question': question,
                            'answer': answer
                        })
                        break
        
        return qa_pairs
    
    def _evaluate_quality(self, qa_pair):
        """è¯„ä¼°é—®ç­”è´¨é‡"""
        # ç®€å•è¯„ä¼°è§„åˆ™ï¼ˆå¯ä»¥ç”¨ LLM å®ç°æ›´å¤æ‚çš„è¯„ä¼°ï¼‰
        answer = qa_pair['answer']
        
        # è¯„åˆ†æ ‡å‡†
        score = 0.5  # åŸºç¡€åˆ†
        
        # ç­”æ¡ˆé•¿åº¦åˆç†
        if 50 <= len(answer) <= 500:
            score += 0.2
        
        # åŒ…å«ä¸“ä¸šæœ¯è¯­
        medical_terms = ['è¯Šæ–­', 'æ²»ç–—', 'æ£€æŸ¥', 'è¯ç‰©', 'ç—‡çŠ¶', 'ç–¾ç—…']
        if any(term in answer for term in medical_terms):
            score += 0.2
        
        # ç»“æ„æ¸…æ™°
        if any(marker in answer for marker in ['1.', '2.', 'é¦–å…ˆ', 'å…¶æ¬¡', 'å»ºè®®']):
            score += 0.1
        
        return min(1.0, score)
```

### 5. åœ¨ LangGraph ä¸­é›†æˆ

åœ¨ `src/graphs/common_opd_graph.py` ä¸­ï¼š

```python
from src.rag.enhanced_rag_retriever import EnhancedRAGRetriever

def create_hospital_graph(config):
    """åˆ›å»ºåŒ»é™¢æµç¨‹å›¾"""
    
    # åˆå§‹åŒ– RAG
    rag = EnhancedRAGRetriever(
        spllm_root=config["rag"]["spllm_root"],
        enable_hybrid=config["rag"].get("enable_hybrid", True),
    )
    
    # å®šä¹‰èŠ‚ç‚¹
    def doctor_consult_node(state):
        """åŒ»ç”Ÿé—®è¯ŠèŠ‚ç‚¹"""
        patient_id = state.get("patient_id")
        symptoms = state.get("symptoms")
        
        # ä½¿ç”¨ RAG æ£€ç´¢
        results = rag.retrieve(
            query=f"æ‚£è€…ç—‡çŠ¶ï¼š{symptoms}",
            filters={"patient_id": patient_id},
            k=5,
            enable_hierarchical=True
        )
        
        # æ›´æ–°çŠ¶æ€
        state["rag_context"] = results
        state["diagnosis"] = generate_diagnosis(symptoms, results)
        
        return state
    
    def finalize_node(state):
        """ç»“æŸèŠ‚ç‚¹ - æ›´æ–°çŸ¥è¯†åº“"""
        # æ›´æ–°æ‚£è€…å†å²
        rag.update_history(
            patient_id=state["patient_id"],
            dialogue_summary=state["dialogue_summary"],
            diagnosis=state.get("diagnosis"),
            treatment=state.get("treatment")
        )
        
        # æ›´æ–°é«˜è´¨é‡é—®ç­”ï¼ˆå¦‚æœæœ‰ï¼‰
        if state.get("qa_pairs"):
            for qa in state["qa_pairs"]:
                rag.update_high_quality_qa(
                    question=qa["question"],
                    answer=qa["answer"],
                    quality_score=qa.get("quality", 0.8)
                )
        
        return state
    
    # æ„å»ºå›¾
    graph = StateGraph(HospitalState)
    graph.add_node("consult", doctor_consult_node)
    graph.add_node("finalize", finalize_node)
    # ... å…¶ä»–èŠ‚ç‚¹
    
    return graph.compile()
```

### 6. é…ç½®æ–‡ä»¶ç¤ºä¾‹

æ›´æ–° `src/config.yaml`ï¼š

```yaml
# RAG é…ç½®
rag:
  retriever_type: "enhanced"
  spllm_root: "./SPLLM-RAG1"
  
  # æ··åˆæ£€ç´¢é…ç½®
  enable_hybrid: true
  bm25_weight: 0.4
  vector_weight: 0.6
  
  # åˆ†å±‚æ£€ç´¢é…ç½®
  enable_hierarchical: true
  
  # æ£€ç´¢å‚æ•°
  cosine_threshold: 0.3
  default_k: 5
  
  # é‡æ’åºï¼ˆå¯é€‰ï¼‰
  enable_rerank: false
  
  # è‡ªè¿›åŒ–é…ç½®
  auto_update_qa: true
  qa_quality_threshold: 0.7
  
  # ç¼“å­˜é…ç½®
  cache_folder: "./SPLLM-RAG1/model_cache"
  embed_model: "BAAI/bge-large-zh-v1.5"
```

### 7. æµ‹è¯•é›†æˆ

åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `tests/test_rag_integration.py`ï¼š

```python
import pytest
from src.rag.enhanced_rag_retriever import EnhancedRAGRetriever

def test_basic_retrieval():
    """æµ‹è¯•åŸºç¡€æ£€ç´¢"""
    rag = EnhancedRAGRetriever(
        spllm_root="./SPLLM-RAG1",
        enable_hybrid=True,
    )
    
    results = rag.retrieve(
        query="å¤´ç—›æ‚£è€…å¦‚ä½•è¯Šæ–­ï¼Ÿ",
        k=3
    )
    
    assert len(results) > 0
    assert all('text' in r for r in results)
    assert all('score' in r for r in results)

def test_patient_history():
    """æµ‹è¯•æ‚£è€…å†å²æ›´æ–°"""
    rag = EnhancedRAGRetriever(spllm_root="./SPLLM-RAG1")
    
    # æ›´æ–°å†å²
    rag.update_history(
        patient_id="TEST_001",
        dialogue_summary="æµ‹è¯•æ‚£è€…å°±è¯Šè®°å½•",
        diagnosis="æµ‹è¯•è¯Šæ–­"
    )
    
    # æ£€ç´¢å†å²
    results = rag.retrieve(
        query="æœ€è¿‘å°±è¯Šè®°å½•",
        filters={"patient_id": "TEST_001"},
        k=2
    )
    
    assert any(r['meta'].get('patient_id') == 'TEST_001' for r in results)

def test_qa_update():
    """æµ‹è¯•é—®ç­”åº“æ›´æ–°"""
    rag = EnhancedRAGRetriever(spllm_root="./SPLLM-RAG1")
    
    rag.update_high_quality_qa(
        question="æµ‹è¯•é—®é¢˜",
        answer="æµ‹è¯•ç­”æ¡ˆ",
        quality_score=0.9
    )
    
    # éªŒè¯å¯ä»¥æ£€ç´¢åˆ°
    results = rag.retrieve(query="æµ‹è¯•é—®é¢˜", k=1)
    assert len(results) > 0
```

è¿è¡Œæµ‹è¯•ï¼š
```bash
pytest tests/test_rag_integration.py -v
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

æ·»åŠ ç›‘æ§ä»£ç ä»¥è·Ÿè¸ª RAG æ€§èƒ½ï¼š

```python
import time
import logging

class RAGMonitor:
    """RAG æ€§èƒ½ç›‘æ§"""
    
    def __init__(self):
        self.logger = logging.getLogger("rag_monitor")
        self.metrics = {
            "total_queries": 0,
            "total_time": 0,
            "avg_results": 0,
        }
    
    def log_query(self, query, results, elapsed_time):
        """è®°å½•æŸ¥è¯¢"""
        self.metrics["total_queries"] += 1
        self.metrics["total_time"] += elapsed_time
        self.metrics["avg_results"] = (
            (self.metrics["avg_results"] * (self.metrics["total_queries"] - 1)
             + len(results)) / self.metrics["total_queries"]
        )
        
        self.logger.info(
            f"æŸ¥è¯¢: {query[:50]}... | "
            f"ç»“æœæ•°: {len(results)} | "
            f"è€—æ—¶: {elapsed_time:.2f}s"
        )
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_queries": self.metrics["total_queries"],
            "avg_time": self.metrics["total_time"] / max(1, self.metrics["total_queries"]),
            "avg_results": self.metrics["avg_results"],
        }

# ä½¿ç”¨ç¤ºä¾‹
monitor = RAGMonitor()

def retrieve_with_monitoring(rag, query, **kwargs):
    """å¸¦ç›‘æ§çš„æ£€ç´¢"""
    start_time = time.time()
    results = rag.retrieve(query, **kwargs)
    elapsed = time.time() - start_time
    
    monitor.log_query(query, results, elapsed)
    return results
```

## âœ… éªŒè¯æ¸…å•

å®Œæˆæ•´åˆåï¼Œæ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š

- [ ] ä¾èµ–å·²å®‰è£…ï¼ˆ`rank-bm25`, `jieba`ï¼‰
- [ ] å‘é‡åº“å·²é‡å»ºï¼ˆä½¿ç”¨åŠ¨æ€åˆ†å—ï¼‰
- [ ] RAG åˆå§‹åŒ–æˆåŠŸ
- [ ] åŸºç¡€æ£€ç´¢æ­£å¸¸
- [ ] æ‚£è€…å†å²è®°å¿†æ­£å¸¸
- [ ] é—®ç­”åº“æ›´æ–°æ­£å¸¸
- [ ] åˆ†å±‚æ£€ç´¢å·¥ä½œæ­£å¸¸
- [ ] æ€§èƒ½å¯æ¥å—ï¼ˆå“åº”æ—¶é—´ < 2ç§’ï¼‰
- [ ] æµ‹è¯•é€šè¿‡

## ğŸ” æ•…éšœæ’æŸ¥

å¦‚é‡é—®é¢˜ï¼ŒæŒ‰ä»¥ä¸‹æ­¥éª¤æ’æŸ¥ï¼š

1. **æ£€æŸ¥ä¾èµ–**
   ```bash
   pip list | grep -E "rank-bm25|jieba"
   ```

2. **æ£€æŸ¥å‘é‡åº“**
   ```bash
   ls -la SPLLM-RAG1/chroma/
   ```

3. **æŸ¥çœ‹æ—¥å¿—**
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

4. **æµ‹è¯•åŸºç¡€åŠŸèƒ½**
   ```bash
   python example_enhanced_rag.py
   ```

## ğŸ“ è·å–å¸®åŠ©

- ğŸ“– æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š`docs/enhanced_rag_system.md`
- ğŸ’» æŸ¥çœ‹ç¤ºä¾‹ä»£ç ï¼š`example_enhanced_rag.py`
- ğŸš€ æŸ¥çœ‹å¿«é€Ÿå¼€å§‹ï¼š`QUICKSTART_RAG.md`
