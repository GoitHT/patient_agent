import os
import fitz  # PyMuPDF
import pandas as pd
import json
import re


# --- 1. æ–‡æœ¬æ¸…æ´—è¾…åŠ©å‡½æ•° ---
def clean_pdf_text(text):
    """
    æ¸…æ´— PDF æå–å‡ºçš„ç¡¬æ¢è¡Œï¼Œåˆå¹¶è¢«æ„å¤–åˆ‡æ–­çš„å¥å­ã€‚
    """
    # 1. æ›¿æ¢è¿ç»­çš„å¤šä¸ªæ¢è¡Œç¬¦ä¸ºç‰¹æ®Šæ ‡è®°ï¼Œä¿æŠ¤çœŸæ­£çš„æ®µè½
    text = re.sub(r'\n\s*\n', '[[PARAGRAPH]]', text)

    # 2. å¤„ç†å•è¡Œæ¢è¡Œ
    lines = text.split('\n')
    cleaned_lines = []

    for i in range(len(lines)):
        line = lines[i].strip()
        if not line:
            continue

        # å¯å‘å¼åˆ¤æ–­ï¼šå¦‚æœå½“å‰è¡Œä¸æ˜¯ä»¥å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€å†’å·ç»“å°¾ï¼Œ
        # è¯´æ˜å®ƒå¾ˆå¯èƒ½å’Œä¸‹ä¸€è¡Œæ˜¯è¿æ¥åœ¨ä¸€èµ·çš„ã€‚
        if not line.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼š', ':', '.', '!', '?')):
            # å¦‚æœåé¢è¿˜æœ‰è¡Œï¼Œåˆ™å»æ‰æ¢è¡Œç¬¦ï¼ˆåŠ ä¸Šç©ºæ ¼æˆ–ç›´æ¥æ‹¼æ¥ï¼‰
            cleaned_lines.append(line)
        else:
            # å¦‚æœæ˜¯æ ‡ç‚¹ç»“å°¾ï¼Œä¿ç•™æ¢è¡Œ
            cleaned_lines.append(line + '\n')

    combined_text = "".join(cleaned_lines)

    # 3. æ¢å¤çœŸæ­£çš„æ®µè½
    combined_text = combined_text.replace('[[PARAGRAPH]]', '\n\n')

    # 4. å»é™¤å¤šä½™çš„ç©ºæ ¼ï¼ˆé’ˆå¯¹è‹±æ–‡æˆ–æ’ç‰ˆäº§ç”Ÿçš„ç¢ç©ºæ ¼ï¼‰
    combined_text = re.sub(r' +', ' ', combined_text)

    return combined_text


# --- 2. PDF æå–æ¨¡å— ---
def sync_pdf_to_txt(source_dir, target_dir):
    if not os.path.exists(source_dir):
        os.makedirs(source_dir)
        return
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)

    pdf_files = [f for f in os.listdir(source_dir) if f.lower().endswith('.pdf')]

    for f in pdf_files:
        txt_filename = os.path.splitext(f)[0] + ".txt"
        target_path = os.path.join(target_dir, txt_filename)
        source_path = os.path.join(source_dir, f)

        if not os.path.exists(target_path):
            print(f"ğŸ”„ [PDF->TXT] æ­£åœ¨æå–å¹¶æ¸…æ´—: {f}")
            try:
                doc = fitz.open(source_path)
                raw_text = ""
                for page in doc:
                    raw_text += page.get_text() + "\n"
                doc.close()

                # --- è°ƒç”¨æ¸…æ´—é€»è¾‘ ---
                final_text = clean_pdf_text(raw_text)

                with open(target_path, 'w', encoding='utf-8') as tf:
                    tf.write(final_text)
                print(f"âœ… å¯¼å‡ºæˆåŠŸ: {txt_filename}")
            except Exception as e:
                print(f"âŒ PDF è½¬æ¢å¤±è´¥ {f}: {e}")
        else:
            print(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨çš„ TXT: {f}")


# --- 3. Excel/CSV è½¬æ¢æ¨¡å— ---
def sync_excel_to_json(source_dir, target_dir):
    if not os.path.exists(source_dir):
        os.makedirs(source_dir)
        return
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)

    # åŒ…å« csv åç¼€
    data_files = [f for f in os.listdir(source_dir) if f.lower().endswith(('.xlsx', '.xls', '.csv'))]

    for f in data_files:
        json_filename = os.path.splitext(f)[0] + ".json"
        target_path = os.path.join(target_dir, json_filename)
        source_path = os.path.join(source_dir, f)

        if not os.path.exists(target_path):
            print(f"ğŸ”„ [Data->JSON] æ­£åœ¨è½¬æ¢: {f}")
            try:
                ext = os.path.splitext(f)[1].lower()
                all_sheets_data = {}

                if ext == '.csv':
                    # --- å¤„ç† CSV ---
                    try:
                        # ä¼˜å…ˆå°è¯• utf-8 (åŒ…å«å¸¦ BOM çš„æ ¼å¼)
                        df = pd.read_csv(source_path, encoding='utf-8-sig')
                    except UnicodeDecodeError:
                        # å¦‚æœå¤±è´¥ï¼Œåˆ‡æ¢åˆ°ä¸­æ–‡å¸¸ç”¨ç¼–ç  gbk æˆ– gb18030
                        df = pd.read_csv(source_path, encoding='gb18030')

                    df = df.fillna("")
                    all_sheets_data["Sheet1"] = df.to_dict(orient='records')

                else:
                    # --- å¤„ç† Excel ---
                    excel_data = pd.read_excel(source_path, sheet_name=None)
                    for sheet_name, df in excel_data.items():
                        df = df.fillna("")
                        all_sheets_data[sheet_name] = df.to_dict(orient='records')

                with open(target_path, 'w', encoding='utf-8') as jf:
                    json.dump(all_sheets_data, jf, ensure_ascii=False, indent=4)
                print(f"âœ… å¯¼å‡ºæˆåŠŸ: {json_filename}")

            except Exception as e:
                print(f"âŒ è½¬æ¢å¤±è´¥ {f}: {e}")
        else:
            print(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨çš„ JSON: {f}")


# --- 4. ç»Ÿä¸€æ‰§è¡Œå…¥å£ ---
if __name__ == "__main__":
    print("=== å¯åŠ¨æ•°æ®é¢„å¤„ç†æµæ°´çº¿ (å¸¦æ–‡æœ¬æ¸…æ´—åŠŸèƒ½) ===")

    # PDF -> TXT (è¯Šç–—è§„èŒƒ)
    PDF_SOURCE = "data/pdf_txt"
    PDF_TARGET = "data/MedicalGuide_data"
    sync_pdf_to_txt(PDF_SOURCE, PDF_TARGET)

    print("-" * 30)

    # Excel -> JSON (ä¸´åºŠç—…ä¾‹)
    EXCEL_SOURCE = "data/excel_json"
    EXCEL_TARGET = "data/ClinicalCase_data"
    sync_excel_to_json(EXCEL_SOURCE, EXCEL_TARGET)

    print("=== é¢„å¤„ç†ä»»åŠ¡å·²å®Œæˆ ===")