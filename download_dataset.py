#!/usr/bin/env python3
"""
ä¸‹è½½ DiagnosisArena æ•°æ®é›†åˆ°æœ¬åœ°

è¿è¡Œæ­¤è„šæœ¬ä¼šå°†å®Œæ•´æ•°æ®é›†ä» HuggingFace ä¸‹è½½å¹¶ä¿å­˜åˆ°æœ¬åœ°ï¼Œ
ä¹‹åè¿è¡Œä¸»ç¨‹åºæ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è”ç½‘ã€‚

ä½¿ç”¨æ–¹æ³•:
    python download_dataset.py                      # ä¸‹è½½åˆ°é»˜è®¤ç›®å½• ./diagnosis_dataset
    python download_dataset.py --output ./data      # ä¸‹è½½åˆ°æŒ‡å®šç›®å½•
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from utils import get_logger

logger = get_logger("dataset_downloader")


def download_dataset(output_dir: str = "./diagnosis_dataset"):
    """
    ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
    """
    try:
        from datasets import load_dataset
        
        output_path = Path(output_dir)
        output_json = output_path / "dataset.json"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if output_json.exists():
            logger.info(f"ğŸ“‚ æ•°æ®é›†å·²å­˜åœ¨: {output_json}")
            response = input("æ˜¯å¦é‡æ–°ä¸‹è½½ï¼Ÿ(y/n): ")
            if response.lower() != 'y':
                logger.info("â¸ï¸  å–æ¶ˆä¸‹è½½")
                return
        
        logger.info("="*80)
        logger.info("ğŸŒ å¼€å§‹ä» HuggingFace ä¸‹è½½æ•°æ®é›†...")
        logger.info("ğŸ“¦ æ•°æ®é›†: SII-SPIRAL-MED/DiagnosisArena")
        logger.info("="*80)
        
        # ä¸‹è½½æ•°æ®é›†
        try:
            dataset = load_dataset("SII-SPIRAL-MED/DiagnosisArena", split="train")
            logger.info(f"âœ… æ•°æ®é›†ä¸‹è½½æˆåŠŸ")
        except (ValueError, KeyError):
            # å¦‚æœæ²¡æœ‰train splitï¼Œå°è¯•åŠ è½½æ•´ä¸ªæ•°æ®é›†
            dataset = load_dataset("SII-SPIRAL-MED/DiagnosisArena")
            # å–ç¬¬ä¸€ä¸ªsplit
            if isinstance(dataset, dict):
                split_name = list(dataset.keys())[0]
                dataset = dataset[split_name]
                logger.info(f"âœ… æ•°æ®é›†ä¸‹è½½æˆåŠŸ (ä½¿ç”¨ split: {split_name})")
        
        logger.info(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        logger.info(f"  - ç—…ä¾‹æ•°: {len(dataset)}")
        logger.info(f"  - å­—æ®µ: {list(dataset.features.keys())}")
        
        # ä¿å­˜åˆ°æœ¬åœ°
        logger.info(f"\nğŸ’¾ ä¿å­˜åˆ°æœ¬åœ°...")
        output_path.mkdir(parents=True, exist_ok=True)
        dataset.to_json(str(output_json), force_ascii=False, indent=2)
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        file_size_mb = output_json.stat().st_size / (1024 * 1024)
        
        logger.info("="*80)
        logger.info("âœ… æ•°æ®é›†ä¸‹è½½å®Œæˆï¼")
        logger.info(f"ğŸ“ ä¿å­˜ä½ç½®: {output_json.absolute()}")
        logger.info(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        logger.info(f"ğŸ“š ç—…ä¾‹æ•°é‡: {len(dataset)}")
        logger.info("="*80)
        
        logger.info("\nğŸ’¡ æç¤º:")
        logger.info("  - ä¸‹æ¬¡è¿è¡Œä¸»ç¨‹åºæ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œæ— éœ€è”ç½‘")
        logger.info("  - å¦‚éœ€æ›´æ–°æ•°æ®é›†ï¼Œè¯·é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        
    except ImportError:
        logger.error("âŒ é”™è¯¯: æœªå®‰è£… datasets åº“")
        logger.info("è¯·è¿è¡Œ: pip install datasets")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        logger.info("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
        logger.info("  1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ— æ³•è®¿é—® HuggingFace")
        logger.info("  2. æ•°æ®é›†ä¸å­˜åœ¨æˆ–å·²ç§»é™¤")
        logger.info("  3. HuggingFace token é…ç½®é—®é¢˜")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½ DiagnosisArena æ•°æ®é›†åˆ°æœ¬åœ°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python download_dataset.py                    # ä½¿ç”¨é»˜è®¤ç›®å½•
  python download_dataset.py --output ./data    # æŒ‡å®šè¾“å‡ºç›®å½•
        """
    )
    
    parser.add_argument(
        "--output",
        type=str,
        default="./diagnosis_dataset",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: ./diagnosis_dataset)"
    )
    
    args = parser.parse_args()
    
    download_dataset(args.output)


if __name__ == "__main__":
    main()
