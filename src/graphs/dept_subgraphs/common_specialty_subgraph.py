"""é€šç”¨ä¸“ç§‘å­å›¾ï¼šæ”¯æŒæ‰€æœ‰ç§‘å®¤çš„ä¸“ç§‘é—®è¯Šã€ä½“æ£€ã€åˆæ­¥åˆ¤æ–­"""
from __future__ import annotations

import json
import random
from typing import Any

from langgraph.graph import END, StateGraph

from graphs.log_helpers import _log_detail
from rag import ChromaRetriever
from services.llm_client import LLMClient
from state.schema import BaseState, make_audit_entry
from utils import load_prompt, contains_any_positive, get_logger
from environment.staff_tracker import StaffTracker  # å¯¼å…¥åŒ»æŠ¤äººå‘˜çŠ¶æ€è¿½è¸ªå™¨
from logging_utils import should_log, OutputFilter, SUPPRESS_UNCHECKED_LOGS  # å¯¼å…¥è¾“å‡ºé…ç½®

# åˆå§‹åŒ–logger
logger = get_logger("hospital_agent.specialty_subgraph")

# åº”ç”¨è¾“å‡ºè¿‡æ»¤å™¨æ¥æŠ‘åˆ¶æœªè¢«should_logåŒ…è£…çš„æ—¥å¿—
if SUPPRESS_UNCHECKED_LOGS:
    logger.addFilter(OutputFilter("specialty_subgraph"))


# Typeæ ‡å‡†åŒ–æ˜ å°„å¸¸é‡ï¼ˆå°†å„ç§å˜ä½“æ˜ å°„åˆ°æ ‡å‡†typeï¼‰
TEST_TYPE_MAPPING = {
    "è¡€æ¶²æ£€æŸ¥": "lab",
    "è¡€æ¶²": "lab",
    "æ£€éªŒ": "lab",
    "å®éªŒå®¤": "lab",
    "åŒ–éªŒ": "lab",
    "å°¿æ¶²æ£€æŸ¥": "lab",
    "å¤§ä¾¿æ£€æŸ¥": "lab",
    "å…ç–«å­¦æ£€æŸ¥": "lab",
    "ç‚ç—‡æ ‡å¿—ç‰©": "lab",
    "è¡€æ¸…å­¦æ£€æŸ¥": "lab",
    "å½±åƒæ£€æŸ¥": "imaging",
    "å½±åƒ": "imaging",
    "æ”¾å°„": "imaging",
    "è¶…å£°": "imaging",
    "å†…é•œæ£€æŸ¥": "endoscopy",
    "å†…é•œ": "endoscopy",
    "é•œæ£€": "endoscopy",
    "åŠŸèƒ½æ£€æŸ¥": "neurophysiology",
    "ç”µç”Ÿç†": "neurophysiology",
    "ç¥ç»ç”µç”Ÿç†": "neurophysiology",
}


def _validate_and_normalize_test(test: dict[str, Any], dept: str, dept_config: dict) -> dict[str, Any] | None:
    """
    æ ‡å‡†åŒ–æ£€æŸ¥é¡¹ç›®ï¼ˆä¸åšç™½åå•æ ¡éªŒï¼Œå®Œå…¨ä¿¡ä»»LLMåˆ¤æ–­ï¼‰
    
    Args:
        test: åŸå§‹æ£€æŸ¥é¡¹ç›®
        dept: ç§‘å®¤ä»£ç 
        dept_config: ç§‘å®¤é…ç½®
        
    Returns:
        æ ‡å‡†åŒ–åçš„æ£€æŸ¥é¡¹ç›®
    """
    test_name = str(test.get("name", "")).strip()
    test_type = str(test.get("type", "lab")).lower()
    
    if not test_name:
        logger.warning(f"  âš ï¸  æ£€æŸ¥é¡¹ç›®åç§°ä¸ºç©ºï¼Œè·³è¿‡")
        return None
    
    # é™åˆ¶æ£€æŸ¥åç§°é•¿åº¦ï¼Œé¿å…JSONè§£æé—®é¢˜
    if len(test_name) > 100:
        logger.warning(f"  âš ï¸  æ£€æŸ¥åç§°è¿‡é•¿({len(test_name)}å­—ç¬¦)ï¼Œæˆªæ–­: {test_name[:50]}...")
        test_name = test_name[:100]
    
    # å¦‚æœtypeä¸æ˜¯æ ‡å‡†å€¼ï¼Œå°è¯•æ˜ å°„
    if test_type not in ["lab", "imaging", "endoscopy", "neurophysiology"]:
        test_type = TEST_TYPE_MAPPING.get(test_type, "lab")  # é»˜è®¤ä¸ºlab
        logger.debug(f"  ğŸ”„ æ£€æŸ¥ç±»å‹æ ‡å‡†åŒ–: {test.get('type')} â†’ {test_type}")
    
    # è·å–æ£€æŸ¥éƒ¨ä½ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    test_body_parts = dept_config.get("test_body_parts", {})
    body_part = test_body_parts.get(test_name, ["ç›¸å…³éƒ¨ä½"])
    
    return {
        "dept": dept,
        "type": test_type,
        "name": test_name,
        "reason": test.get("reason", "è¿›ä¸€æ­¥æ˜ç¡®è¯Šæ–­"),
        "priority": test.get("priority", "routine"),
        "need_prep": bool(test.get("need_prep", test_type in ["endoscopy"])),
        "need_schedule": bool(test.get("need_schedule", test_type in ["endoscopy", "neurophysiology"])),
        "body_part": body_part,
    }


def _chunks_for_prompt(chunks: list[dict[str, Any]], *, max_chars: int = 1400) -> str:
    lines: list[str] = []
    total = 0
    for c in chunks:
        text = str(c.get("text") or "").replace("\n", " ").strip()
        line = f"[{c.get('doc_id')}#{c.get('chunk_id')}] {text[:240]}"
        lines.append(line)
        total += len(line) + 1
        if total >= max_chars:
            break
    return "\n".join(lines)


# ç§‘å®¤é…ç½®æ˜ å°„ï¼ˆå½“å‰åªä¿ç•™ neurologyï¼Œå…¶ä»–ç§‘å®¤é…ç½®å·²åˆ é™¤ä»¥å‡å°‘å†—ä½™ï¼‰
DEPT_CONFIG = {
    "neurology": {
        "name": "ç¥ç»åŒ»å­¦",
        "interview_keys": ["onset_time", "frequency", "severity", "triggers", "relievers", "red_flags"],
        "alarm_keywords": ["çªå‘", "åç˜«", "è‚¢ä½“æ— åŠ›", "è¨€è¯­ä¸æ¸…", "æ„è¯†éšœç¢", "æŠ½æ"],
        "exam_area": "neurological",
        "common_tests": ["å¤´é¢…CT", "å¤´é¢…MRI", "è„‘ç”µå›¾", "è‚Œç”µå›¾"],
    },
}


def build_common_specialty_subgraph(
    *, 
    retriever: ChromaRetriever,
    llm: LLMClient | None = None,
    doctor_agent=None, 
    patient_agent=None, 
    max_questions: int = 3  # æœ€åº•å±‚é»˜è®¤å€¼ï¼Œé€šå¸¸ä»config.yamlä¼ å…¥
):
    """æ„å»ºé€šç”¨ä¸“ç§‘å­å›¾ï¼Œé€‚ç”¨äºæ‰€æœ‰ç§‘å®¤
    
    Args:
        max_questions: åŒ»ç”Ÿæœ€å¤šé—®è¯Šæ¬¡æ•°ï¼ˆä»config.agent.max_questionsä¼ å…¥ï¼‰
    """
    graph = StateGraph(BaseState)
    
    # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œåˆ¤æ–­ use_agentsï¼Œè€Œæ˜¯åœ¨èŠ‚ç‚¹æ‰§è¡Œæ—¶åŠ¨æ€åˆ¤æ–­
    # å› ä¸º doctor_agent æ˜¯åœ¨ C4 èŠ‚ç‚¹ä¸­åŠ¨æ€åˆ†é…åˆ° state çš„

    def s4_specialty_interview(state: BaseState) -> BaseState:
        """S4: é€šç”¨ä¸“ç§‘é—®è¯ŠèŠ‚ç‚¹"""
        dept = state.dept
        dept_config = DEPT_CONFIG.get(dept, DEPT_CONFIG.get("internal_medicine", {}))
        dept_name = dept_config.get("name", "é€šç”¨ç§‘å®¤")
        
        # ç»ˆç«¯ç®€æ´è¾“å‡º
        if should_log(1, "specialty_subgraph", "S4"):
            logger.info(f"ğŸ« S4: {dept_name}ä¸“ç§‘é—®è¯Š")
        
        # è¯¦ç»†æ—¥å¿—è®°å½•
        detail_logger = state.patient_detail_logger if hasattr(state, 'patient_detail_logger') else None
        if detail_logger:
            detail_logger.section(f"{dept_name}ä¸“ç§‘é—®è¯Š")
        
        # åŠ¨æ€åˆ¤æ–­æ˜¯å¦å¯ç”¨Agentæ¨¡å¼ï¼ˆæ£€æŸ¥stateä¸­æ˜¯å¦æœ‰Agentï¼‰
        use_agents = (hasattr(state, 'doctor_agent') and state.doctor_agent is not None and
                     hasattr(state, 'patient_agent') and state.patient_agent is not None)
        
        # ä» state ä¸­è·å–åŒ»ç”Ÿ Agentï¼ˆC4 èŠ‚ç‚¹ä¸­åˆ†é…çš„ï¼‰
        doctor_agent = None
        patient_agent = None
        if use_agents:
            doctor_agent = state.doctor_agent
            patient_agent = state.patient_agent
            if hasattr(state, 'assigned_doctor_name'):
                logger.info(f"  ğŸ‘¨â€âš•ï¸ ä½¿ç”¨ C4 åˆ†é…çš„åŒ»ç”Ÿ Agent: {state.assigned_doctor_name}")
            else:
                logger.info(f"  ğŸ‘¨â€âš•ï¸ ä½¿ç”¨åŒ»ç”Ÿ Agent è¿›è¡Œé—®è¯Š")
        else:
            logger.info(f"  â„¹ï¸  Agentæ¨¡å¼æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨LLMæ¨¡å¼")
            if detail_logger:
                detail_logger.info("æœªæ£€æµ‹åˆ°Doctor Agentæˆ–Patient Agentï¼Œä½¿ç”¨LLMæ¨¡å¼æå–ä¿¡æ¯")
        
        # å¦‚æœæ˜¯Agentæ¨¡å¼ï¼Œç¡®ä¿åŒ»ç”Ÿæ™ºèƒ½ä½“çš„ç§‘å®¤è®¾ç½®æ­£ç¡®
        if use_agents and doctor_agent:
            doctor_agent.dept = dept
            logger.info(f"  ğŸ¥ åŒ»ç”Ÿç§‘å®¤: {dept_name}")
        
        # æ£€ç´¢è¯¥ç§‘å®¤çš„ä¸“ç§‘çŸ¥è¯†
        # æ³¨æ„ï¼šæ­¤æ—¶chief_complaintè¿˜æœªè®¾ç½®ï¼ˆåŒ»ç”Ÿå°šæœªä»æ‚£è€…å¤„è·å¾—ï¼‰ï¼Œä½¿ç”¨ç§‘å®¤ä¿¡æ¯æ£€ç´¢
        query = f"{dept} {dept_name} çº¢æ—— æ£€æŸ¥å»ºè®® é‰´åˆ«è¯Šæ–­"
        logger.info(f"ğŸ” æ£€ç´¢{dept_name}çŸ¥è¯†...")
        chunks = retriever.retrieve(query, filters={"dept": dept}, k=4)
        state.add_retrieved_chunks(chunks)

        cc = state.chief_complaint
        
        # è·å–ç§‘å®¤é…ç½®ç”¨äºæç¤ºè¯
        alarm_keywords = dept_config.get("alarm_keywords", [])
        interview_keys = dept_config.get("interview_keys", ["symptoms_detail"])

        # è·å–èŠ‚ç‚¹ä¸“å±è®¡æ•°å™¨
        node_key = f"s4_{dept}"
        
        # Agentæ¨¡å¼ï¼šé€æ­¥ä¸€é—®ä¸€ç­”ï¼Œç„¶åä»doctor_agentæ”¶é›†ç»“æ„åŒ–ä¿¡æ¯
        if use_agents:
            # è·å–æœ€å¤§é—®è¯Šè½®æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨state.agent_configï¼Œå…¶æ¬¡ä½¿ç”¨å‡½æ•°å‚æ•°ï¼‰
            # ç¡®ä¿ä½¿ç”¨é…ç½®æ–‡ä»¶è®¾ç½®çš„å€¼ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç çš„é»˜è®¤å€¼
            if state.agent_config and "max_questions" in state.agent_config:
                max_qs = state.agent_config["max_questions"]
            else:
                max_qs = max_questions  # ä½¿ç”¨å‡½æ•°å‚æ•°ï¼ˆæ¥è‡ªé…ç½®æ–‡ä»¶ï¼‰
            
            # å¼€å§‹é—®è¯Š
            logger.info(f"  ğŸ’¬ é—®è¯Šå¼€å§‹")
            
            if detail_logger:
                detail_logger.subsection("åŒ»ç”Ÿé—®è¯Š")
            
            # ===== ç‰©ç†ç¯å¢ƒé›†æˆï¼šé—®è¯Šå‰æ£€æŸ¥æ‚£è€…çŠ¶æ€ =====
            if state.world_context:
                # æ£€æŸ¥ç‰©ç†çŠ¶æ€å½±å“ï¼ˆé™é»˜å¤„ç†ï¼Œä»…è®°å½•ç´§æ€¥æƒ…å†µï¼‰
                impact = state.get_physical_impact_on_diagnosis()
                if impact.get("has_impact"):
                    # è°ƒæ•´é—®è¯Šè½®æ•°ï¼ˆå†…éƒ¨é€»è¾‘ï¼Œä¸æ˜¾ç¤ºï¼‰
                    physical_max_questions = impact.get("max_questions", max_qs)
                    if physical_max_questions < max_qs:
                        max_qs = physical_max_questions
                    
                    # ä»…è®°å½•ç´§æ€¥æƒ…å†µï¼ˆæ„è¯†å¼‚å¸¸ï¼‰
                    if impact.get("emergency"):
                        logger.error("ğŸš¨ ç´§æ€¥æƒ…å†µï¼šæ‚£è€…æ„è¯†å¼‚å¸¸ï¼Œå»ºè®®ç«‹å³è½¬æ€¥è¯Š")
                        state.escalations.append("æ‚£è€…æ„è¯†å¼‚å¸¸ï¼Œå»ºè®®æ€¥è¯Šè¯„ä¼°")
                        max_qs = 0
            
            # ä½¿ç”¨å…¨å±€å…±äº«è®¡æ•°å™¨
            global_qa_count = state.node_qa_counts.get("global_total", 0)
            questions_asked_this_node = state.node_qa_counts.get(node_key, 0)
            
            # è®¡ç®—æœ¬èŠ‚ç‚¹å‰©ä½™é—®é¢˜æ•°ï¼šæœ¬èŠ‚ç‚¹é…é¢ - æœ¬èŠ‚ç‚¹å·²é—®æ•°
            # ä¸ä½¿ç”¨å…¨å±€è®¡æ•°å™¨é™åˆ¶ï¼Œå› ä¸ºæ¯ä¸ªä¸“ç§‘èŠ‚ç‚¹åº”è¯¥æœ‰ç‹¬ç«‹çš„é—®è¯Šæœºä¼š
            remaining_questions = max(0, max_qs - questions_asked_this_node)
            
            if detail_logger:
                detail_logger.info(f"å…¨å±€å·²é—® {global_qa_count} ä¸ªï¼Œæœ¬èŠ‚ç‚¹å·²é—® {questions_asked_this_node} ä¸ªï¼Œæœ¬èŠ‚ç‚¹å‰©ä½™ {remaining_questions} ä¸ª")
            
            # å¦‚æœå‰©ä½™é—®é¢˜æ•°ä¸º0ï¼Œè®°å½•åŸå› 
            if remaining_questions == 0:
                reason = ""
                if max_qs == 0:
                    reason = "max_questionsé…ç½®ä¸º0æˆ–å› ç´§æ€¥æƒ…å†µè·³è¿‡é—®è¯Š"
                elif questions_asked_this_node >= max_qs:
                    reason = f"æœ¬èŠ‚ç‚¹å·²å®Œæˆå…¨éƒ¨ {max_qs} è½®é—®è¯Š"
                
                logger.info(f"  â„¹ï¸  è·³è¿‡é—®è¯Šï¼š{reason}")
                if detail_logger:
                    detail_logger.info(f"âš ï¸ è·³è¿‡é—®è¯Šï¼š{reason}")

            
            # é€ä¸ªç”Ÿæˆé—®é¢˜å¹¶è·å–å›ç­”
            qa_list = state.agent_interactions.get("doctor_patient_qa", [])
            
            # è·å–æ‚£è€…è¯¦ç»†æ—¥å¿—è®°å½•å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            detail_logger = state.patient_detail_logger if hasattr(state, 'patient_detail_logger') else None
            
            for i in range(remaining_questions):
                # ç»ˆç«¯åªæ˜¾ç¤ºç®€æ´ä¿¡æ¯
                if should_log(1, "specialty_subgraph", "S4"):
                    logger.info(f"  ğŸ’¬ é—®è¯Šç¬¬ {questions_asked_this_node + i + 1} è½®")
                
                # åŒ»ç”ŸåŸºäºå½“å‰ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªé—®é¢˜
                context_desc = f"{dept_name}ä¸“ç§‘é—®è¯Šï¼Œå…³æ³¨ï¼š{', '.join(interview_keys)}"
                if alarm_keywords:
                    context_desc += f"ï¼Œè­¦æŠ¥ç—‡çŠ¶ï¼š{', '.join(alarm_keywords)}"
                
                # ç¬¬ä¸€ä¸ªé—®é¢˜ï¼šåŒ»ç”Ÿæ€»æ˜¯å…ˆç”¨å¼€æ”¾å¼é—®é¢˜è¯¢é—®æ‚£è€…å“ªé‡Œä¸èˆ’æœ
                # è¿™ç¬¦åˆçœŸå®åŒ»ç–—åœºæ™¯ï¼šåŒ»ç”Ÿé¦–å…ˆè®©æ‚£è€…è‡ªå·±æè¿°ä¸»è¦ç—‡çŠ¶
                if i == 0 and not doctor_agent.questions_asked:
                    question = "æ‚¨å¥½ï¼Œè¯·é—®æ‚¨å“ªé‡Œä¸èˆ’æœï¼Ÿ"
                else:
                    # åç»­é—®é¢˜ï¼šä½¿ç”¨æ”¶é›†åˆ°çš„ä¿¡æ¯ç”Ÿæˆé’ˆå¯¹æ€§é—®é¢˜
                    # æ³¨æ„ï¼šä¸ç›´æ¥ä½¿ç”¨state.chief_complaintï¼Œè€Œæ˜¯ä½¿ç”¨doctor_agentå·²æ”¶é›†çš„ä¿¡æ¯
                    question = doctor_agent.generate_one_question(
                        chief_complaint=doctor_agent.collected_info.get("chief_complaint", ""),
                        context=context_desc,
                        rag_chunks=chunks
                    )
                
                if not question:
                    if should_log(1, "specialty_subgraph", "S4"):
                        logger.info("  â„¹ï¸  åŒ»ç”Ÿæå‰ç»“æŸé—®è¯Š")
                    if detail_logger:
                        detail_logger.info("åŒ»ç”Ÿåˆ¤æ–­ä¿¡æ¯å·²å……è¶³ï¼Œæå‰ç»“æŸé—®è¯Š")
                    break
                
                # æ‚£è€…å›ç­”ï¼ˆä¼ å…¥ç‰©ç†çŠ¶æ€ï¼‰
                physical_state = state.physical_state_snapshot if state.world_context else None
                answer = patient_agent.respond_to_doctor(question, physical_state=physical_state)
                
                # è¯¦ç»†æ—¥å¿—ï¼šè®°å½•å®Œæ•´çš„é—®è¯Šå¯¹è¯
                if detail_logger:
                    detail_logger.qa_round(questions_asked_this_node + i + 1, question, answer)
                
                # åŒ»ç”Ÿå¤„ç†å›ç­”
                doctor_agent.process_patient_answer(question, answer)
                
                # ã€é‡è¦ã€‘åŒæ­¥æ›´æ–°åŒ»ç”Ÿçš„å¯¹è¯å†å²è®°å½•ï¼ˆç”¨äºä¸‹æ¬¡ç”Ÿæˆé—®é¢˜æ—¶å‚è€ƒï¼‰
                doctor_agent.collected_info.setdefault("conversation_history", [])
                doctor_agent.collected_info["conversation_history"].append({
                    "question": question,
                    "answer": answer
                })
                
                # è®°å½•å¯¹è¯åˆ°state
                qa_list.append({
                    "question": question, 
                    "answer": answer, 
                    "stage": f"{dept}_specialty"
                })
                
                # æ›´æ–°è¯¥èŠ‚ç‚¹å’Œå…¨å±€è®¡æ•°å™¨
                state.node_qa_counts[node_key] = questions_asked_this_node + i + 1
                state.node_qa_counts["global_total"] = global_qa_count + i + 1
            
            state.agent_interactions["doctor_patient_qa"] = qa_list
            
            # ===== StaffTrackeré›†æˆï¼šåŒºç”Ÿä¸“ç§‘é—®è¯Šå·¥ä½œ =====
            if state.world_context:
                actual_questions = state.node_qa_counts.get(node_key, 0) - questions_asked_this_node
                if actual_questions > 0:
                    # æ¯è½®é—®è¯Šçº¦2-3åˆ†é’Ÿ
                    consultation_time = actual_questions * 2.5
                    StaffTracker.update_doctor_consultation(
                        world=state.world_context,
                        duration_minutes=int(consultation_time),
                        complexity=0.6  # ä¸“ç§‘é—®è¯Šå¤æ‚åº¦ä¸­ç­‰åä¸Š
                    )
                    logger.info(f"  ğŸ‘¨â€âš•ï¸  åŒ»ç”Ÿå®Œæˆ{dept_name}ä¸“ç§‘é—®è¯Šï¼ˆ{actual_questions}è½®ï¼Œè€—æ—¶{int(consultation_time)}åˆ†é’Ÿï¼‰")
            
            # ===== ç‰©ç†ç¯å¢ƒé›†æˆï¼šé—®è¯Šåæ›´æ–°ç‰©ç†çŠ¶æ€ =====
            if state.world_context:
                qa_count = len([qa for qa in qa_list if qa.get('stage') == f"{dept}_specialty"])
                if qa_count > 0:
                    duration = qa_count * 3  # æ¯è½®çº¦3åˆ†é’Ÿ
                    energy_cost = 0.5 * qa_count  # æ¯è½®æ¶ˆè€—0.5ä½“åŠ›
                    
                    logger.info(f"\n{'â”€'*60}")
                    logger.info(f"ğŸŒ ç‰©ç†ç¯å¢ƒæ¨¡æ‹Ÿ - é—®è¯Šè¿‡ç¨‹")
                    logger.info(f"{'â”€'*60}")
                    start_time = state.world_context.current_time.strftime('%H:%M')
                    
                    result = state.update_physical_world(
                        action="consult",
                        duration_minutes=duration,
                        energy_cost=energy_cost
                    )
                    end_time = state.world_context.current_time.strftime('%H:%M')
                    
                    logger.info(f"ğŸ’¬ é—®è¯Šè½®æ•°: {qa_count}è½®")
                    logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration}åˆ†é’Ÿ")
                    logger.info(f"ğŸ• æ—¶é—´: {start_time} â†’ {end_time}")
                    logger.info(f"{'â”€'*60}")
                    
                    # å¦‚æœå‡ºç°å±æ€¥è­¦æŠ¥
                    if result.get("critical_warning"):
                        logger.warning(f"ğŸš¨ è­¦å‘Šï¼šæ‚£è€…å‡ºç°å±æ€¥çŠ¶æ€ (æ„è¯†: {result.get('consciousness')})")
            
            # ä»åŒ»ç”Ÿæ”¶é›†çš„ä¿¡æ¯æ›´æ–°state
            state.history.update(doctor_agent.collected_info.get("history", {}))
            
            final_qa_count = state.node_qa_counts.get(node_key, 0)
            final_global_count = state.node_qa_counts.get("global_total", 0)
            logger.info(f"  âœ… {dept_name}ä¸“ç§‘é—®è¯Šå®Œæˆï¼Œæœ¬èŠ‚ç‚¹ {final_qa_count} è½®ï¼Œå…¨å±€æ€»è®¡ {final_global_count} è½®")
            
            # ===== åŒ»ç”Ÿæ€»ç»“ä¸“ä¸šä¸»è¯‰ =====
            # æ€»æ˜¯è®©åŒ»ç”ŸåŸºäºé—®è¯Šæ€»ç»“ä¸“ä¸šä¸»è¯‰ï¼Œè¦†ç›–æ‚£è€…å‘æŠ¤å£«è¯´çš„å£è¯­åŒ–æè¿°
            summarized_cc = doctor_agent.summarize_chief_complaint()
            if summarized_cc:
                # ä¿å­˜åŸå§‹ä¸»è¯‰ï¼ˆæ‚£è€…å‘æŠ¤å£«è¯´çš„ï¼‰ä¾›å‚è€ƒ
                if state.chief_complaint and state.chief_complaint != summarized_cc:
                    state.original_chief_complaint = state.chief_complaint
                # æ›´æ–°ä¸ºåŒ»ç”Ÿæ€»ç»“çš„ä¸“ä¸šä¸»è¯‰
                state.chief_complaint = summarized_cc
                logger.info(f"\n  ğŸ“‹ åŒ»ç”Ÿæ€»ç»“ä¸»è¯‰ï¼ˆä¸“ä¸šç‰ˆï¼‰: {summarized_cc}")
                
                # æ›´æ–°æ•°æ®åº“ä¸­çš„chief_complaintå­—æ®µ
                if hasattr(state, 'medical_record_integration') and state.medical_record_integration:
                    record = state.medical_record_integration.mrs.get_record(state.patient_id)
                    if record:
                        state.medical_record_integration.mrs.dao.update_medical_case(record.record_id, {
                            "chief_complaint": summarized_cc
                        })
            
            # ===== æ–°å¢ï¼šé—®è¯Šè´¨é‡è¯„ä¼° =====
            # åªæœ‰åœ¨å®é™…é—®äº†é—®é¢˜æ—¶æ‰æ˜¾ç¤ºè¯„ä¼°
            if len(doctor_agent.questions_asked) > 0:
                logger.info(f"\n{'â”'*60}")
                logger.info("ğŸ“Š é—®è¯Šè´¨é‡è¯„ä¼°")
                logger.info(f"{'â”'*60}")
                
                quality_report = doctor_agent.assess_interview_quality()
                
                # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                logger.info(f"  ğŸ“ˆ ç»¼åˆè¯„åˆ†: {quality_report['overall_score']}/100")
                logger.info(f"     â€¢ å®Œæ•´æ€§: {quality_report['completeness_score']:.0f}/100")
                logger.info(f"     â€¢ æ·±åº¦: {quality_report['depth_score']:.0f}/100")
                logger.info(f"     â€¢ æ•ˆç‡: {quality_report['efficiency_score']:.0f}/100")
                
                if quality_report['warning']:
                    if quality_report['overall_score'] < 50:
                        logger.warning(f"  {quality_report['warning']}")
                    elif quality_report['overall_score'] < 70:
                        logger.info(f"  {quality_report['warning']}")
                    else:
                        logger.info(f"  {quality_report['warning']}")
                
                # æ˜¾ç¤ºç¼ºå¤±ä¿¡æ¯
                if quality_report['missing_areas']:
                    logger.info(f"\n  âŒ ç¼ºå¤±å…³é”®ä¿¡æ¯ ({len(quality_report['missing_areas'])}é¡¹):")
                    for area in quality_report['missing_areas']:
                        logger.info(f"     â€¢ {area}")
                
                # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
                if quality_report['suggestions']:
                    logger.info(f"\n  ğŸ’¡ æ”¹è¿›å»ºè®®:")
                    for suggestion in quality_report['suggestions'][:3]:  # æœ€å¤šæ˜¾ç¤º3æ¡
                        logger.info(f"     â€¢ {suggestion}")
                
                logger.info(f"{'â”'*60}\n")
                
                # ä¿å­˜è¯„ä¼°ç»“æœåˆ°state
                state.agent_interactions["interview_quality"] = quality_report
            
            # Agentæ¨¡å¼ï¼šç›´æ¥ä»åŒ»ç”Ÿæ™ºèƒ½ä½“è·å–ç»“æ„åŒ–ä¿¡æ¯ï¼Œä¸å†ç”¨LLMé‡å¤æå–
            interview = doctor_agent.collected_info.get(f"{dept}_interview", {})
            if not interview:
                # å¦‚æœåŒ»ç”Ÿæ²¡æœ‰ç‰¹å®šç§‘å®¤ä¿¡æ¯ï¼Œä½¿ç”¨é€šç”¨history
                interview = {
                    "collected_from_agent": True,
                    "alarm_symptoms": [],  # Agentä¼šåœ¨å¯¹è¯ä¸­å¤„ç†è­¦æŠ¥ç—‡çŠ¶
                }
                # åªæ›´æ–°éè­¦æŠ¥ç—‡çŠ¶ç›¸å…³çš„å­—æ®µï¼ˆé¿å…å°†"ä¸è¯¦"å­—ç¬¦ä¸²èµ‹å€¼ç»™è­¦æŠ¥ç—‡çŠ¶å­—æ®µï¼‰
                for key in interview_keys:
                    if key not in ["alarm_symptoms", "red_flags"]:
                        interview[key] = doctor_agent.collected_info.get("history", {}).get(key, "ä¸è¯¦")
            
            # ä» Agent æ”¶é›†ä¿¡æ¯
            if detail_logger:
                detail_logger.info("\nä» Agentæ”¶é›†çš„ä¸“ç§‘ä¿¡æ¯å·²æ•´åˆ")
        
        # éAgentæ¨¡å¼ï¼šä½¿ç”¨LLMæå–ä¸“ç§‘ä¿¡æ¯
        else:
            # ä½¿ç”¨LLMæå–
            if detail_logger:
                detail_logger.subsection("ä½¿ç”¨LLMæå–ä¸“ç§‘ä¿¡æ¯")
            system_prompt = load_prompt("common_system.txt")
            
            # æ ¹æ®ç§‘å®¤é€‰æ‹©ä¸åŒçš„prompt
            specialty_prompt_file = f"{dept}_specialty.txt"
            try:
                specialty_prompt = load_prompt(specialty_prompt_file)
            except:
                specialty_prompt = f"è¯·æå–{dept_name}ç›¸å…³çš„ä¸“ç§‘ä¿¡æ¯ã€‚"
            
            # ç®€åŒ–çš„æç¤ºè¯
            user_prompt = (
                specialty_prompt
                + f"\n\nã€ä»»åŠ¡ã€‘ä»ç—…ä¾‹ä¸­æå–{dept_name}ä¸“ç§‘ç»“æ„åŒ–ä¿¡æ¯\n"
                + f"ã€å…³æ³¨ç‚¹ã€‘{', '.join(interview_keys)}\n"
                + f"ã€è­¦æŠ¥ç—‡çŠ¶ã€‘{', '.join(alarm_keywords)}\n\n"
                + f"ã€ç—…ä¾‹ã€‘{cc}\n\n"
                + "ã€å‚è€ƒçŸ¥è¯†ã€‘\n" + _chunks_for_prompt(chunks) + "\n\n"
                + f"ã€è¾“å‡ºã€‘JSONæ ¼å¼ï¼Œå­—æ®µå: {dept}_interviewï¼ŒåŒ…å«ä¸Šè¿°å…³æ³¨ç‚¹åŠalarm_symptomsåˆ—è¡¨"
            )
            
            obj, used_fallback, _raw = llm.generate_json(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                fallback=lambda: {f"{dept}_interview": {key: "ä¸è¯¦" for key in interview_keys} | {"alarm_symptoms": []}},
                temperature=0.2,
            )
            interview = dict(obj.get(f"{dept}_interview") or {})
            # æå–å®Œæˆ
            if detail_logger:
                detail_logger.info("ä¸“ç§‘ä¿¡æ¯æå–å®Œæˆ")

        state.dept_payload.setdefault(dept, {})
        state.dept_payload[dept]["interview"] = interview

        # ç»Ÿä¸€è­¦æŠ¥ç—‡çŠ¶æ£€æµ‹ï¼ˆä»LLMè¿”å›çš„interviewä¸­è·å–ï¼‰
        # å®‰å…¨åœ°æå–è­¦æŠ¥ç—‡çŠ¶ï¼Œæ£€æŸ¥ç±»å‹é¿å…å°†å­—ç¬¦ä¸²æ‹†åˆ†æˆå­—ç¬¦åˆ—è¡¨
        raw_alarms = interview.get("alarm_symptoms") or interview.get("red_flags") or []
        if isinstance(raw_alarms, list):
            alarm_list = [str(a) for a in raw_alarms if a]  # è¿‡æ»¤ç©ºå€¼
        elif isinstance(raw_alarms, str) and raw_alarms not in ["ä¸è¯¦", "æ— ", ""]:
            alarm_list = [raw_alarms]  # å•ä¸ªå­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨
        else:
            alarm_list = []  # å¿½ç•¥å…¶ä»–æ— æ•ˆå€¼
        
        if alarm_list:
            if detail_logger:
                detail_logger.warning(f"âš ï¸  å‘ç°è­¦æŠ¥ç—‡çŠ¶: {', '.join(str(a) for a in alarm_list)}")
            # ç»ˆç«¯è¾“å‡ºï¼ˆéœ€è¦output level >= 2ï¼‰
            if should_log(2, "specialty_subgraph", "S4"):
                logger.warning(f"  âš ï¸  å‘ç°è­¦æŠ¥ç—‡çŠ¶: {', '.join(str(a) for a in alarm_list)}")

        # è®°å½•èŠ‚ç‚¹é—®ç­”è½®æ•°
        node_qa_turns = state.node_qa_counts.get(node_key, 0)
        
        # ===== ä¿å­˜é—®è¯Šè®°å½•åˆ°æ•°æ®åº“ =====
        if hasattr(state, 'medical_record_integration') and state.medical_record_integration:
            state.medical_record_integration.on_doctor_consultation(state, doctor_id="doctor_001")
        
        state.add_audit(
            make_audit_entry(
                node_name=f"S4 {dept_name} Specialty Interview",
                inputs_summary={"chief_complaint": state.chief_complaint, "use_agents": use_agents, "dept": dept, "max_questions": max_questions},
                outputs_summary={"alarm_symptoms": alarm_list, "node_qa_turns": node_qa_turns},
                decision=f"å®Œæˆ{dept_name}ä¸“ç§‘é—®è¯Šï¼ˆæœ¬èŠ‚ç‚¹{node_qa_turns}è½®ï¼‰" + ("ï¼ˆAgentæ¨¡å¼ï¼‰" if use_agents else ("ï¼ˆLLMæ¨¡å¼ï¼‰" if not used_fallback else "ï¼ˆFallbackï¼‰")),
                chunks=chunks,
                flags=["AGENT_MODE"] if use_agents else (["LLM_PARSE_FALLBACK"] if used_fallback else ["LLM_USED"]),
            )
        )
        
        # è¯¦ç»†æ—¥å¿—è¾“å‡ºèŠ‚ç‚¹æ‰§è¡Œæ‘˜è¦
        if detail_logger:
            detail_logger.info("")
            detail_logger.info("ğŸ“¤ S4 ä¸“ç§‘é—®è¯Šè¾“å‡º:")
            detail_logger.info(f"  â€¢ é—®è¯Šè½®æ•°: {node_qa_turns}è½®")
            if alarm_list:
                detail_logger.info(f"  â€¢ å±é™©ç—‡çŠ¶: {', '.join(alarm_list)}")
            if use_agents and doctor_agent:
                collected = doctor_agent.collected_info
                if collected.get('chief_complaint'):
                    detail_logger.info(f"  â€¢ ä¸»è¯‰: {collected['chief_complaint']}")
                if collected.get('history', {}).get('duration'):
                    detail_logger.info(f"  â€¢ ç—…ç¨‹: {collected['history']['duration']}")
            detail_logger.info(f"âœ… S4 ä¸“ç§‘é—®è¯Šå®Œæˆ")
            detail_logger.info("")
        
        if should_log(1, "specialty_subgraph", "S4"):
            logger.info(f"  âœ… S4å®Œæˆ\n")
        return state

    def s5_physical_exam(state: BaseState) -> BaseState:
        """S5: é€šç”¨ä½“æ£€èŠ‚ç‚¹"""
        dept = state.dept
        dept_config = DEPT_CONFIG.get(dept, DEPT_CONFIG.get("internal_medicine", {}))
        dept_name = dept_config.get("name", "é€šç”¨")
        exam_area = dept_config.get("exam_area", "general")
        alarm_keywords = dept_config.get("alarm_keywords", [])
        
        # è·å–è¯¦ç»†æ—¥å¿—è®°å½•å™¨
        detail_logger = state.patient_detail_logger if hasattr(state, 'patient_detail_logger') else None
        
        if should_log(1, "specialty_subgraph", "S5"):
            logger.info(f"ï¿½ S5: {dept_name}ä½“æ ¼æ£€æŸ¥")
        
        if detail_logger:
            detail_logger.section(f"{dept_name}ä½“æ ¼æ£€æŸ¥")
        
        # å½“å‰æ•°æ®æºåªæœ‰case_characterï¼Œä½¿ç”¨LLMç”Ÿæˆä½“æ£€ç»“æœ
        data_source = "llm_generated"
        real_physical_exam = None  # æ•°æ®é›†ä¸­æ²¡æœ‰ä½“æ ¼æ£€æŸ¥æ•°æ®
        
        logger.info(f"ğŸ“‹ ä½¿ç”¨LLMç”Ÿæˆä½“æ£€ç»“æœ")
        
        # ç»Ÿä¸€ç»“æ„åŒ–å¤„ç†æµç¨‹
        system_prompt = load_prompt("common_system.txt")
        
        # LLMç”Ÿæˆï¼šåŸºäºä¸»è¯‰å’Œä¸“ç§‘ä¿¡æ¯
        interview_info = state.dept_payload.get(dept, {}).get("interview", {})
        interview_str = json.dumps(interview_info, ensure_ascii=False) if interview_info else "æ— "
        
        # è·å–é—®è¯Šå¯¹è¯å†å²ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡
        qa_history = ""
        if state.agent_interactions.get("doctor_patient_qa"):
            qa_list = [qa for qa in state.agent_interactions["doctor_patient_qa"] if qa.get('stage') == f"{dept}_specialty"]
            if qa_list:
                qa_history = "\nã€é—®è¯Šå¯¹è¯ã€‘\n"
                for i, qa in enumerate(qa_list[:3], 1):  # æœ€å¤šæ˜¾ç¤º3è½®å¯¹è¯
                    qa_history += f"Q{i}: {qa.get('question', '')}\n"
                    qa_history += f"A{i}: {qa.get('answer', '')}\n"
        
        user_prompt = (
                f"æ ¹æ®{dept_name}ç§‘å®¤ç‰¹ç‚¹å’Œæ‚£è€…ä¸»è¯‰ï¼Œç”Ÿæˆç¬¦åˆä¸´åºŠå®é™…çš„ä½“æ ¼æ£€æŸ¥ç»“æœã€‚\n\n"
                + f"ã€ä¸»è¯‰ã€‘{state.chief_complaint}\n"
                + f"ã€ä¸“ç§‘é—®è¯Šã€‘{interview_str}\n"
                + qa_history
                + f"\nã€è¦æ±‚ã€‘\n"
                + f"1. ç”Ÿå‘½ä½“å¾ï¼ˆvital_signsï¼‰ï¼šä½“æ¸©ã€è„‰æã€è¡€å‹ã€å‘¼å¸é¢‘ç‡ç­‰ï¼Œç»™å‡ºå…·ä½“æ•°å€¼\n"
                + f"2. ä¸€èˆ¬æƒ…å†µï¼ˆgeneralï¼‰ï¼šç¥å¿—ã€ç²¾ç¥çŠ¶æ€ã€è¥å…»çŠ¶å†µã€ä½“å‹ç­‰ï¼Œæè¿°å…·ä½“\n"
                + f"3. {exam_area}ä¸“ç§‘ä½“æ£€ï¼šæ ¹æ®ä¸»è¯‰å’Œç§‘å®¤ç‰¹ç‚¹ï¼Œç”Ÿæˆç›¸å…³é˜³æ€§æˆ–é˜´æ€§ä½“å¾\n"
                + f"4. é˜³æ€§ä½“å¾ä¸ä¸»è¯‰ç›¸ç¬¦ï¼Œé˜´æ€§ä½“å¾ç”¨äºæ’é™¤ç›¸å…³ç–¾ç—…\n"
                + f"5. è€ƒè™‘è­¦æŠ¥ç—‡çŠ¶ï¼š{', '.join(alarm_keywords)}\n"
                + f"6. ä½“æ£€ç»“æœåº”çœŸå®å¯ä¿¡ï¼Œç¬¦åˆåŒ»å­¦å¸¸è¯†\n\n"
                + "ã€è¾“å‡ºã€‘JSONæ ¼å¼ï¼š\n"
                + "{\n"
                + "  \"exam\": {\n"
                + "    \"vital_signs\": {\n"
                + "      \"temperature\": \"36.5Â°C\",\n"
                + "      \"pulse\": \"78æ¬¡/åˆ†\",\n"
                + "      \"blood_pressure\": \"120/80mmHg\",\n"
                + "      \"respiration\": \"18æ¬¡/åˆ†\"\n"
                + "    },\n"
                + "    \"general\": \"ç¥å¿—æ¸…æ¥šï¼Œç²¾ç¥å¯ï¼Œè¥å…»ä¸­ç­‰ï¼Œä½“å‹æ­£å¸¸\",\n"
                + f"    \"{exam_area}_exam\": {{å…·ä½“ä¸“ç§‘ä½“æ£€é¡¹ç›®åŠç»“æœ}},\n"
                + "    \"positive_signs\": [\"é˜³æ€§ä½“å¾1\", \"é˜³æ€§ä½“å¾2\"],\n"
                + "    \"negative_signs\": [\"é˜´æ€§ä½“å¾1\", \"é˜´æ€§ä½“å¾2\"]\n"
                + "  }\n"
                + "}\n\n"
                + "âš ï¸ æ³¨æ„ï¼šæ‰€æœ‰æ•°å€¼å’Œæè¿°åº”åŸºäºä¸»è¯‰åˆç†æ¨æµ‹ï¼Œä¸è¦ç”Ÿæˆä¸ç›¸å…³çš„å¼‚å¸¸"
        )
        fallback_data = {
            "exam": {
                "vital_signs": {"temperature": "æ­£å¸¸", "pulse": "æ­£å¸¸", "blood_pressure": "æ­£å¸¸"},
                "general": "ä¸€èˆ¬æƒ…å†µå¯",
                "note": f"{dept_name}ä½“æ ¼æ£€æŸ¥"
            }
        }
        temp = 0.2
        
        # æ£€æŸ¥LLMæ˜¯å¦å¯ç”¨
        if llm is None:
            logger.error("âš ï¸  æœªLLMé…ç½®ï¼Œæ— æ³•ç”Ÿæˆä½“æ ¼æ£€æŸ¥ç»“æœ")
            exam = fallback_data["exam"]
            exam["source"] = "no_llm"
            used_fallback = True
            
            # ä½¿ç”¨fallbackæ—¶ä¹Ÿè¾“å‡ºåˆ°æ‚£è€…æ—¥å¿—
            if detail_logger:
                detail_logger.warning("âš ï¸  LLMä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤ä½“æ£€ç»“æœ")
                detail_logger.info("\nğŸ“‹ ä½“æ ¼æ£€æŸ¥ç»“æœ:")
                detail_logger.info(f"  ã€ä¸€èˆ¬æƒ…å†µã€‘{exam.get('general', 'æ— ')}")
                if exam.get('vital_signs'):
                    detail_logger.info(f"  ã€ç”Ÿå‘½ä½“å¾ã€‘æ­£å¸¸èŒƒå›´")
        else:
            # æ‰§è¡ŒLLMè°ƒç”¨
            obj, used_fallback, _raw = llm.generate_json(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                fallback=lambda: fallback_data,
                temperature=temp,
            )
            exam = dict(obj.get("exam") or {})
            exam["source"] = data_source
            logger.info("  âœ… ä½“æ ¼æ£€æŸ¥å¤„ç†å®Œæˆ")
            
            # è¾“å‡ºä½“æ£€ç»“æœåˆ°æ‚£è€…æ—¥å¿—
            if detail_logger and exam:
                detail_logger.info("\nğŸ“‹ ä½“æ ¼æ£€æŸ¥ç»“æœ:")
                
                # ç”Ÿå‘½ä½“å¾
                vital_signs = exam.get("vital_signs", {})
                if vital_signs:
                    detail_logger.info("  ã€ç”Ÿå‘½ä½“å¾ã€‘")
                    for key, value in vital_signs.items():
                        detail_logger.info(f"    â€¢ {key}: {value}")
                
                # ä¸€èˆ¬æƒ…å†µ
                general = exam.get("general")
                if general:
                    detail_logger.info(f"  ã€ä¸€èˆ¬æƒ…å†µã€‘{general}")
                
                # ä¸“ç§‘ä½“æ£€
                specialty_exam = exam.get(f"{exam_area}_exam")
                if specialty_exam:
                    detail_logger.info(f"  ã€{dept_name}ä¸“ç§‘ä½“æ£€ã€‘")
                    if isinstance(specialty_exam, dict):
                        for key, value in specialty_exam.items():
                            detail_logger.info(f"    â€¢ {key}: {value}")
                    else:
                        detail_logger.info(f"    {specialty_exam}")
                
                # é˜³æ€§ä½“å¾
                positive_signs = exam.get("positive_signs", [])
                if positive_signs:
                    detail_logger.info("  ã€é˜³æ€§ä½“å¾ã€‘")
                    for sign in positive_signs:
                        detail_logger.info(f"    âœ“ {sign}")
                
                # é˜´æ€§ä½“å¾
                negative_signs = exam.get("negative_signs", [])
                if negative_signs:
                    detail_logger.info("  ã€é˜´æ€§ä½“å¾ã€‘")
                    for sign in negative_signs:  # æ˜¾ç¤ºæ‰€æœ‰é˜´æ€§ä½“å¾
                        detail_logger.info(f"    - {sign}")
        
        state.exam_findings.setdefault(exam_area, {})
        state.exam_findings[exam_area] = exam
        
        # æ¨è¿›æ—¶é—´ï¼ˆä½“æ ¼æ£€æŸ¥çº¦5åˆ†é’Ÿï¼‰
        if state.world_context:
            state.world_context.advance_time(minutes=5)
            state.sync_physical_state()

        state.add_audit(
            make_audit_entry(
                node_name=f"S5 {dept_name} Physical Exam",
                inputs_summary={"exam_area": exam_area, "dept": dept, "has_real_data": bool(real_physical_exam)},
                outputs_summary={"exam_completed": True, "data_source": exam.get("source", "unknown")},
                decision=f"å®Œæˆ{dept_name}ä½“æ ¼æ£€æŸ¥è®°å½•" + ("ï¼ˆä½¿ç”¨æ•°æ®é›†çœŸå®æ•°æ®ï¼‰" if real_physical_exam else "ï¼ˆLLMç”Ÿæˆï¼‰"),
                chunks=[],
                flags=["REAL_DATA"] if real_physical_exam else (["LLM_PARSE_FALLBACK"] if used_fallback else ["LLM_USED"]),
            )
        )
        
        # æ‚£è€…æ—¥å¿—æ€»ç»“
        if detail_logger:
            detail_logger.info(f"âœ… S5 {dept_name}ä½“æ ¼æ£€æŸ¥å®Œæˆ")
            detail_logger.info("")
        
        logger.info("âœ… S5èŠ‚ç‚¹å®Œæˆ\n")
        return state

    def s6_preliminary_judgment(state: BaseState) -> BaseState:
        """S6: é€šç”¨åˆæ­¥åˆ¤æ–­ä¸å¼€å•èŠ‚ç‚¹"""
        dept = state.dept
        dept_config = DEPT_CONFIG.get(dept, DEPT_CONFIG.get("internal_medicine", {}))
        dept_name = dept_config.get("name", "é€šç”¨")
        alarm_keywords = dept_config.get("alarm_keywords", [])
        common_tests = dept_config.get("common_tests", ["è¡€å¸¸è§„"])
                # è·å–è¯¦ç»†æ—¥å¿—è®°å½•å™¨
        detail_logger = state.patient_detail_logger if hasattr(state, 'patient_detail_logger') else None
        logger.info("\n" + "="*60)
        logger.info(f"ï¿½ S6: {dept_name}åˆæ­¥åˆ¤æ–­")
        logger.info("="*60)
        
        query = f"{dept} {dept_name} æ£€æŸ¥é€‰æ‹© é€‚åº”ç—‡ {state.chief_complaint}"
        logger.info(f"ğŸ” æ£€ç´¢{dept_name}æ£€æŸ¥æŒ‡å—...")
        chunks = retriever.retrieve(query, filters={"dept": dept}, k=4)
        state.add_retrieved_chunks(chunks)

        cc = state.chief_complaint
        
        # ä½¿ç”¨LLMç”Ÿæˆæ£€æŸ¥æ–¹æ¡ˆ
        logger.info("\nğŸ¤– ä½¿ç”¨LLMç”Ÿæˆæ£€æŸ¥æ–¹æ¡ˆ...")
        system_prompt = load_prompt("common_system.txt")
        
        # å°è¯•åŠ è½½ç§‘å®¤ç‰¹å®šprompt
        specialty_prompt_file = f"{dept}_specialty.txt"
        try:
            specialty_prompt = load_prompt(specialty_prompt_file)
        except:
            specialty_prompt = f"è¯·æ ¹æ®{dept_name}ç—‡çŠ¶åˆ¶å®šæ£€æŸ¥æ–¹æ¡ˆã€‚"
        
        # å¼ºåŒ–æç¤ºè¯ï¼šæ˜ç¡®typeæ ‡å‡†ï¼Œç²¾å‡†å¼€å…·å…³é”®æ£€æŸ¥
        user_prompt = (
            specialty_prompt
            + "\n\nã€ä»»åŠ¡ã€‘æ ¹æ®æ‚£è€…æƒ…å†µï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¾…åŠ©æ£€æŸ¥å¹¶ç»™å‡ºåˆæ­¥è¯„ä¼°ã€‚\n\n"
            + "ã€æ ¸å¿ƒåŸåˆ™ï¼šç²¾å‡†å¼€å•ï¼Œé¿å…è¿‡åº¦æ£€æŸ¥ã€‘\n"
            + "1. ä¼˜å…ˆçº§è¯„ä¼°ï¼š\n"
            + "   - ä»…å¼€å…·å¯¹æ˜ç¡®è¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆæœ‰å®è´¨æ€§å¸®åŠ©çš„æ£€æŸ¥\n"
            + "   - æ¯é¡¹æ£€æŸ¥éƒ½åº”æœ‰æ¸…æ™°çš„ä¸´åºŠç›®çš„å’Œè¯Šæ–­ä»·å€¼\n"
            + "   - é¿å…ã€Œé¢„é˜²æ€§ã€æˆ–ã€Œä»¥é˜²ä¸‡ä¸€ã€çš„æ£€æŸ¥\n\n"
            + "2. æ£€æŸ¥æ•°é‡æ§åˆ¶ï¼š\n"
            + "   - é¦–æ¬¡å°±è¯Šé€šå¸¸1-3é¡¹æ ¸å¿ƒæ£€æŸ¥å³å¯\n"
            + "   - ç—‡çŠ¶æ˜ç¡®ä¸”è½»å¾®ï¼šå¯ä¸å¼€æ£€æŸ¥ï¼Œç»™äºˆå¯¹ç—‡å»ºè®®\n"
            + "   - ç—‡çŠ¶å¤æ‚æˆ–æœ‰è­¦æŠ¥ä¿¡å·ï¼šå¼€å…·2-4é¡¹é’ˆå¯¹æ€§æ£€æŸ¥\n"
            + "   - é¿å…ã€Œæ£€æŸ¥å¥—é¤ã€å¼çš„å¤§è§„æ¨¡ç­›æŸ¥\n\n"
            + "3. ä¸´åºŠå†³ç­–é€»è¾‘ï¼š\n"
            + f"   - è­¦æŠ¥ç—‡çŠ¶ï¼ˆå¿…é¡»é‡è§†ï¼‰ï¼š{', '.join(alarm_keywords)}\n"
            + f"   - å¸¸è§„åŸºç¡€æ£€æŸ¥å‚è€ƒï¼š{', '.join(common_tests[:2])}ï¼ˆä»…åœ¨å¿…è¦æ—¶å¼€å…·ï¼‰\n"
            + "   - å½±åƒå­¦æ£€æŸ¥ï¼ˆCT/MRIï¼‰ï¼šä»…åœ¨é«˜åº¦æ€€ç–‘ç»“æ„æ€§ç—…å˜æ—¶å¼€å…·\n"
            + "   - ç”µç”Ÿç†æ£€æŸ¥ï¼ˆEEG/EMGï¼‰ï¼šä»…åœ¨æ˜ç¡®ç¥ç»åŠŸèƒ½è¯„ä¼°éœ€æ±‚æ—¶å¼€å…·\n\n"
            + "4. å†³ç­–ç¤ºä¾‹ï¼š\n"
            + "   - è½»åº¦å¤´ç—›ï¼Œæ— è­¦æŠ¥ç—‡çŠ¶ â†’ ä¸å¼€æ£€æŸ¥ï¼Œè§‚å¯Ÿéšè®¿\n"
            + "   - å¤´ç—›ä¼´å‘•åã€è§†ç‰©æ¨¡ç³Š â†’ è¡€å¸¸è§„+å¤´é¢…CTï¼ˆæ’é™¤é¢…å†…ç—…å˜ï¼‰\n"
            + "   - ç™«ç—«å‘ä½œå² â†’ EEGï¼ˆè¯„ä¼°å¼‚å¸¸æ”¾ç”µï¼‰\n"
            + "   - å››è‚¢éº»æœ¨æ— åŠ› â†’ è‚Œç”µå›¾ï¼ˆè¯„ä¼°å‘¨å›´ç¥ç»ï¼‰\n\n"
            + "ã€æ‚£è€…ä¿¡æ¯ã€‘\n"
            + json.dumps(
                {
                    "chief_complaint": state.chief_complaint,
                    "history": state.history,
                    "exam_findings": state.exam_findings,
                    f"{dept}_interview": state.dept_payload.get(dept, {}).get("interview", {}),
                },
                ensure_ascii=False,
                indent=2
            )
            + "\n\nã€å‚è€ƒçŸ¥è¯†ã€‘\n" + _chunks_for_prompt(chunks)
            + "\n\nã€è¾“å‡ºè¦æ±‚ã€‘å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦é—æ¼ä»»ä½•é€—å·æˆ–æ‹¬å·ï¼‰ï¼š\n"
            + "{\n"
            + "  \"need_aux_tests\": true/false,\n"
            + "  \"ordered_tests\": [\n"
            + "    {\n"
            + "      \"dept\": \"ç§‘å®¤ä»£ç \",\n"
            + "      \"type\": \"lab\"/\"imaging\"/\"endoscopy\"/\"neurophysiology\",\n"
            + "      \"name\": \"æ£€æŸ¥åç§°\",\n"
            + "      \"reason\": \"å¼€å…·åŸå› \",\n"
            + "      \"priority\": \"urgent\"/\"routine\",\n"
            + "      \"need_prep\": true/false,\n"
            + "      \"need_schedule\": true/false\n"
            + "    }\n"
            + "  ],\n"
            + "  \"specialty_summary\": {\n"
            + "    \"problem_list\": [\"é—®é¢˜1\", \"é—®é¢˜2\"],\n"
            + "    \"assessment\": \"è¯„ä¼°å†…å®¹\",\n"
            + "    \"plan_direction\": \"è®¡åˆ’æ–¹å‘\",\n"
            + "    \"red_flags\": [\"è­¦æŠ¥ä¿¡å·1\"]\n"
            + "  }\n"
            + "}\n\n"
            + "âš ï¸ å…³é”®è¦æ±‚ï¼š\n"
            + "1. typeå­—æ®µå¿…é¡»æ˜¯ï¼šlab/imaging/endoscopy/neurophysiologyï¼ˆå°å†™è‹±æ–‡ï¼‰\n"
            + "2. need_prepå’Œneed_scheduleå¿…é¡»æ˜¯å¸ƒå°”å€¼ï¼ˆtrue/falseï¼Œå°å†™ï¼‰\n"
            + "3. æ¯ä¸ªå¯¹è±¡å†…éƒ¨æœ€åä¸€ä¸ªå­—æ®µåé¢ä¸è¦åŠ é€—å·\n"
            + "4. æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ åé¢ä¸è¦åŠ é€—å·\n"
            + "5. ç¡®ä¿æ‰€æœ‰æ‹¬å·å’Œå¼•å·æ­£ç¡®é…å¯¹\n"
            + "6. æ£€æŸ¥nameåº”ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ï¼ˆå¦‚ï¼š\"è¡€å¸¸è§„\"ã€\"å¤´é¢…MRI\"ã€\"æŠ—æ ¸æŠ—ä½“\"ï¼‰"
        )
        
        # æ£€æŸ¥LLMæ˜¯å¦å¯ç”¨
        if llm is None:
            logger.error("âš ï¸  æœªLLMé…ç½®ï¼Œæ— æ³•ç”Ÿæˆæ£€æŸ¥æ–¹æ¡ˆ")
            # ä½¿ç”¨ä¿å®ˆçš„fallback
            obj = {
                "need_aux_tests": False,
                "ordered_tests": [],
                "specialty_summary": {
                    "problem_list": [f"{dept_name}ç—‡çŠ¶å¾…è¯„ä¼°"],
                    "assessment": "LLMä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ£€æŸ¥æ–¹æ¡ˆ",
                    "plan_direction": "éœ€é…ç½®LLM",
                    "red_flags": []
                },
            }
            used_fallback = True
        else:
            # ä¼˜åŒ–fallbackä¸ºä¿å®ˆç­–ç•¥
            obj, used_fallback, _raw = llm.generate_json(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            fallback=lambda: {
                "need_aux_tests": False,  # æ”¹ä¸ºä¿å®ˆç­–ç•¥ï¼šä¸ç¡®å®šæ—¶ä¸å¼€å•
                "ordered_tests": [],
                "specialty_summary": {
                    "problem_list": [f"{dept_name}ç—‡çŠ¶å¾…è¯„ä¼°"],
                    "assessment": "ä¿¡æ¯ä¸è¶³ï¼Œå»ºè®®è¿›ä¸€æ­¥é—®è¯Š",
                    "plan_direction": "å®Œå–„ç—…å²é‡‡é›†",
                    "red_flags": []
                },
            },
            temperature=0.2,
        )
        need_aux_tests = bool(obj.get("need_aux_tests", False))
        ordered = list(obj.get("ordered_tests") or [])
        summary = dict(obj.get("specialty_summary") or {})
        logger.info("  âœ… æ£€æŸ¥æ–¹æ¡ˆç”Ÿæˆå®Œæˆ")
        
        # æ¨è¿›æ—¶é—´ï¼ˆåŒ»ç”Ÿåˆæ­¥åˆ¤æ–­ä¸å¼€å•çº¦5åˆ†é’Ÿï¼‰
        if state.world_context:
            state.world_context.advance_time(minutes=5)
            state.sync_physical_state()

        # æ ‡å‡†åŒ–æ£€æŸ¥é¡¹ç›®ï¼ˆä¸åšç™½åå•è¿‡æ»¤ï¼Œå®Œå…¨ä¿¡ä»»LLMåˆ¤æ–­ï¼‰
        normalized: list[dict[str, Any]] = []
        for t in ordered:
            if not isinstance(t, dict):
                continue
            normalized_test = _validate_and_normalize_test(t, dept, dept_config)
            if normalized_test:
                normalized.append(normalized_test)
            else:
                logger.warning(f"  âš ï¸  æ£€æŸ¥é¡¹ç›® '{t.get('name')}' æ ‡å‡†åŒ–å¤±è´¥ï¼Œè·³è¿‡")
        
        ordered = normalized
        
        # å¦‚æœæ ‡å‡†åŒ–åæ²¡æœ‰é¡¹ç›®ï¼Œæ›´æ–°çŠ¶æ€
        if need_aux_tests and not ordered:
            logger.warning("  âš ï¸  åŸè®¡åˆ’å¼€å•ä½†æ ‡å‡†åŒ–åæ— æœ‰æ•ˆé¡¹ç›®ï¼Œæ”¹ä¸ºä¸å¼€å•")
            need_aux_tests = False
        
        # æ›´æ–°çŠ¶æ€
        state.need_aux_tests = need_aux_tests
        state.ordered_tests = ordered
        state.specialty_summary = summary
        
        decision = "éœ€è¦è¾…åŠ©æ£€æŸ¥ä»¥æ˜ç¡®è¯Šæ–­" if need_aux_tests else "æš‚æ— éœ€è¾…åŠ©æ£€æŸ¥ï¼Œç»™å‡ºå¯¹ç—‡æ–¹å‘"
        
        logger.info(f"\n  ğŸ“‹ å¼€å•å†³ç­–: need_aux_tests={state.need_aux_tests}")
        if ordered:
            logger.info(f"  ğŸ“ å¼€å•é¡¹ç›® ({len(ordered)}é¡¹):")
            for test in ordered:
                logger.info(f"     - {test['name']} ({test['type']}) - {test.get('priority', 'routine')}")

        state.dept_payload.setdefault(dept, {})
        state.dept_payload[dept]["preliminary"] = {
            "need_aux_tests": state.need_aux_tests,
            "ordered_tests_count": len(ordered),
        }

        state.add_audit(
            make_audit_entry(
                node_name=f"S6 {dept_name} Preliminary Judgment",
                inputs_summary={"chief_complaint": state.chief_complaint, "dept": dept},
                outputs_summary={
                    "need_aux_tests": state.need_aux_tests,
                    "ordered_tests": [t["name"] for t in ordered],
                },
                decision=decision,
                chunks=chunks,
                flags=["LLM_PARSE_FALLBACK"] if used_fallback else ["LLM_USED"],
            )
        )
        
        # è¯¦ç»†æ—¥å¿—è¾“å‡ºèŠ‚ç‚¹æ‰§è¡Œæ‘˜è¦
        if detail_logger:
            detail_logger.info("")
            detail_logger.info("ğŸ“¤ S6 åˆæ­¥åˆ¤æ–­è¾“å‡º:")
            detail_logger.info(f"  â€¢ éœ€è¦è¾…åŠ©æ£€æŸ¥: {'æ˜¯' if need_aux_tests else 'å¦'}")
            if ordered:
                detail_logger.info(f"  â€¢ å¼€å…·æ£€æŸ¥: {len(ordered)}é¡¹")
                for test in ordered[:3]:  # æœ€å¤šæ˜¾ç¤º3é¡¹
                    detail_logger.info(f"      - {test['name']} ({test['type']})")
                if len(ordered) > 3:
                    detail_logger.info(f"      ... è¿˜æœ‰ {len(ordered) - 3} é¡¹")
            if summary:
                if summary.get('problem_list'):
                    detail_logger.info(f"  â€¢ é—®é¢˜åˆ—è¡¨: {', '.join(summary['problem_list'][:3])}")
                if summary.get('assessment'):
                    detail_logger.info(f"  â€¢ è¯„ä¼°: {summary['assessment'][:80]}...")
            detail_logger.info(f"âœ… S6 åˆæ­¥åˆ¤æ–­å®Œæˆ")
            detail_logger.info("")
        
        logger.info("âœ… S6èŠ‚ç‚¹å®Œæˆ\n")
        return state

    # æ„å»ºå›¾ç»“æ„
    graph.add_node("S4", s4_specialty_interview)
    graph.add_node("S5", s5_physical_exam)
    graph.add_node("S6", s6_preliminary_judgment)

    graph.set_entry_point("S4")
    graph.add_edge("S4", "S5")
    graph.add_edge("S5", "S6")
    graph.add_edge("S6", END)
    
    return graph.compile()
