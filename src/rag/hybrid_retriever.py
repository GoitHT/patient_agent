"""æ··åˆæ£€ç´¢å™¨ - èåˆ BM25 å’Œå‘é‡æ£€ç´¢
å®ç°èåˆæ£€ç´¢ç­–ç•¥ï¼Œç»“åˆå…³é”®è¯åŒ¹é…å’Œè¯­ä¹‰æ£€ç´¢çš„ä¼˜åŠ¿
"""
from __future__ import annotations

import os
import logging
from pathlib import Path
from typing import Any, List, Dict
from collections import defaultdict

# å¼ºåˆ¶ä½¿ç”¨ç¦»çº¿æ¨¡å¼
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'

# ç¦ç”¨ä¸å¿…è¦çš„è­¦å‘Š
logging.getLogger("chromadb").setLevel(logging.ERROR)


class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ - BM25 + å‘é‡æ£€ç´¢èåˆ
    
    ç‰¹æ€§ï¼š
        - BM25 å…³é”®è¯åŒ¹é…ï¼ˆå¤„ç†ä¸“ä¸šæœ¯è¯­ã€ç–¾ç—…åç§°ç­‰ï¼‰
        - å‘é‡è¯­ä¹‰æ£€ç´¢ï¼ˆç†è§£è¯­ä¹‰ç›¸ä¼¼æ€§ï¼‰
        - å€’æ•°æ’åºèåˆï¼ˆReciprocal Rank Fusionï¼‰
        - åŠ¨æ€æƒé‡è°ƒèŠ‚
        - å¤šçŸ¥è¯†åº“æ”¯æŒï¼šåŒ»å­¦æŒ‡å—ã€ä¸´åºŠæ¡ˆä¾‹ã€é—®ç­”ã€å†å²ã€åŒ»é™¢æµç¨‹
    
    çŸ¥è¯†åº“è¯´æ˜ï¼š
        - MedicalGuide_db: åŒ»å­¦ä¸“ä¸šæŒ‡å—ã€è¯Šç–—è§„èŒƒã€æ£€æŸ¥æŒ‡å¾
        - HospitalProcess_db: åŒ»é™¢é€šç”¨æµç¨‹ã€è¡¨å•æ¨¡æ¿ã€SOPæ–‡æ¡£
        - ClinicalCase_db: ä¸´åºŠæ¡ˆä¾‹åº“
        - HighQualityQA_db: é«˜è´¨é‡é—®ç­”åº“
        - UserHistory_db: æ‚£è€…å†å²è®°å½•
    """
    
    def __init__(
        self,
        *,
        spllm_root: Path | str,
        cache_folder: Path | str | None = None,
        cosine_threshold: float = 0.3,
        embed_model: str = "BAAI/bge-large-zh-v1.5",
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6,
        k1: float = 1.5,  # BM25 å‚æ•°
        b: float = 0.75,  # BM25 å‚æ•°
    ):
        """
        Args:
            spllm_root: SPLLM-RAG1 é¡¹ç›®æ ¹ç›®å½•
            cache_folder: æ¨¡å‹ç¼“å­˜ç›®å½•
            cosine_threshold: ä½™å¼¦è·ç¦»é˜ˆå€¼
            embed_model: åµŒå…¥æ¨¡å‹åç§°
            bm25_weight: BM25 æ£€ç´¢æƒé‡ï¼ˆ0-1ï¼‰
            vector_weight: å‘é‡æ£€ç´¢æƒé‡ï¼ˆ0-1ï¼‰
            k1: BM25 è¯é¢‘é¥±å’Œå‚æ•°
            b: BM25 æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–å‚æ•°
        """
        self.spllm_root = Path(spllm_root).resolve()
        self.cache_folder = Path(cache_folder) if cache_folder else self.spllm_root / "model_cache"
        self.cosine_threshold = cosine_threshold
        self.embed_model = embed_model
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        self.k1 = k1
        self.b = b
        
        # è®¾ç½®ç¼“å­˜è·¯å¾„
        os.environ['HF_HOME'] = str(self.cache_folder)
        
        # å»¶è¿Ÿå¯¼å…¥
        self._embeddings = None
        self._dbs = {}
        self._bm25_indices = {}  # BM25 ç´¢å¼•ç¼“å­˜
        
        # æ—¥å¿—
        self._logger = logging.getLogger("hospital_agent.hybrid_rag")
        self._logger.info(f"ğŸ”„ æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–: BM25={bm25_weight}, Vector={vector_weight}")
    
    def _init_embeddings(self):
        """å»¶è¿Ÿåˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        if self._embeddings is not None:
            return
        
        try:
            # ä¸´æ—¶å±è”½åµŒå…¥æ¨¡å‹çš„åŠ è½½æ—¥å¿—
            import logging as std_logging
            sentence_transformers_logger = std_logging.getLogger('sentence_transformers')
            transformers_logger = std_logging.getLogger('transformers')
            old_st_level = sentence_transformers_logger.level
            old_tf_level = transformers_logger.level
            sentence_transformers_logger.setLevel(std_logging.WARNING)
            transformers_logger.setLevel(std_logging.WARNING)
            
            from langchain_huggingface import HuggingFaceEmbeddings
            
            self._embeddings = HuggingFaceEmbeddings(
                model_name=self.embed_model,
                model_kwargs={"device": "cpu"},
                encode_kwargs={
                    "normalize_embeddings": True,
                    "batch_size": 32
                },
                cache_folder=str(self.cache_folder)
            )
            
            # æ¢å¤æ—¥å¿—çº§åˆ«
            sentence_transformers_logger.setLevel(old_st_level)
            transformers_logger.setLevel(old_tf_level)
            
            test_vec = self._embeddings.embed_query("æµ‹è¯•")
            self._logger.info(f"âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆç»´åº¦={len(test_vec)}ï¼‰")
        except Exception as e:
            # æ¢å¤æ—¥å¿—çº§åˆ«ï¼ˆå³ä½¿å‡ºé”™ï¼‰
            try:
                sentence_transformers_logger.setLevel(old_st_level)
                transformers_logger.setLevel(old_tf_level)
            except:
                pass
            self._logger.error(f"âŒ åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {e}")
    
    def _get_db(self, db_name: str):
        """è·å–æˆ–åŠ è½½å‘é‡åº“"""
        if db_name in self._dbs:
            return self._dbs[db_name]
        
        self._init_embeddings()
        
        try:
            from langchain_chroma import Chroma
            
            db_path = self.spllm_root / "chroma" / db_name
            if not db_path.exists():
                self._logger.warning(f"âš ï¸  å‘é‡åº“è·¯å¾„ä¸å­˜åœ¨: {db_path}")
                return None
            
            db = Chroma(
                persist_directory=str(db_path),
                embedding_function=self._embeddings,
                collection_metadata={"hnsw:space": "cosine"}
            )
            self._dbs[db_name] = db
            self._logger.debug(f"âœ… å‘é‡åº“åŠ è½½æˆåŠŸ: {db_name}")
            return db
        except Exception as e:
            self._logger.error(f"âŒ å‘é‡åº“ {db_name} åŠ è½½å¤±è´¥: {e}")
            return None
    
    def _get_bm25_index(self, db_name: str):
        """è·å–æˆ–æ„å»º BM25 ç´¢å¼•"""
        if db_name in self._bm25_indices:
            return self._bm25_indices[db_name]
        
        db = self._get_db(db_name)
        if not db:
            return None
        
        try:
            from rank_bm25 import BM25Okapi
            import jieba
            
            # è·å–å‘é‡åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£
            collection = db._collection
            all_docs = collection.get(include=["documents", "metadatas"])
            
            if not all_docs or not all_docs.get("documents"):
                self._logger.warning(f"âš ï¸  å‘é‡åº“ {db_name} æ— æ–‡æ¡£")
                return None
            
            # åˆ†è¯æ„å»º BM25 ç´¢å¼•
            documents = all_docs["documents"]
            metadatas = all_docs.get("metadatas", [])
            
            tokenized_corpus = [list(jieba.cut(doc)) for doc in documents]
            bm25 = BM25Okapi(tokenized_corpus, k1=self.k1, b=self.b)
            
            # ç¼“å­˜ç´¢å¼•å’ŒåŸå§‹æ–‡æ¡£
            self._bm25_indices[db_name] = {
                "bm25": bm25,
                "documents": documents,
                "metadatas": metadatas,
                "tokenized_corpus": tokenized_corpus
            }
            
            self._logger.debug(f"âœ… BM25 ç´¢å¼•æ„å»ºæˆåŠŸ: {db_name}ï¼ˆ{len(documents)} æ–‡æ¡£ï¼‰")
            return self._bm25_indices[db_name]
        
        except ImportError:
            self._logger.error("âŒ ç¼ºå°‘ä¾èµ–ï¼špip install rank-bm25 jieba")
            return None
        except Exception as e:
            self._logger.error(f"âŒ BM25 ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
            return None
    
    def _bm25_search(self, query: str, db_name: str, k: int = 10) -> List[Dict[str, Any]]:
        """BM25 å…³é”®è¯æ£€ç´¢"""
        index_data = self._get_bm25_index(db_name)
        if not index_data:
            return []
        
        try:
            import jieba
            
            bm25 = index_data["bm25"]
            documents = index_data["documents"]
            metadatas = index_data["metadatas"]
            
            # æŸ¥è¯¢åˆ†è¯
            query_tokens = list(jieba.cut(query))
            scores = bm25.get_scores(query_tokens)
            
            # è·å– top-k ç»“æœ
            top_indices = scores.argsort()[-k:][::-1]
            
            results = []
            for idx in top_indices:
                if scores[idx] > 0:  # åªä¿ç•™æœ‰å¾—åˆ†çš„ç»“æœ
                    results.append({
                        "text": documents[idx],
                        "meta": metadatas[idx] if idx < len(metadatas) else {},
                        "score": float(scores[idx]),
                        "source": "bm25"
                    })
            
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  BM25 æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _vector_search(self, query: str, db_name: str, k: int = 10) -> List[Dict[str, Any]]:
        """å‘é‡è¯­ä¹‰æ£€ç´¢"""
        db = self._get_db(db_name)
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold * 2:  # æ”¾å®½é˜ˆå€¼ä»¥ä¾¿èåˆ
                    similarity = max(0, 1 - distance)
                    results.append({
                        "text": doc.page_content,
                        "meta": doc.metadata,
                        "score": float(similarity),
                        "source": "vector"
                    })
            
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _reciprocal_rank_fusion(
        self,
        bm25_results: List[Dict[str, Any]],
        vector_results: List[Dict[str, Any]],
        k: int = 60
    ) -> List[Dict[str, Any]]:
        """å€’æ•°æ’åºèåˆï¼ˆRRFï¼‰ç®—æ³•
        
        RRF åˆ†æ•° = sum(1 / (k + rank_i))ï¼Œå…¶ä¸­ k æ˜¯å¸¸æ•°ï¼ˆé€šå¸¸ä¸º 60ï¼‰
        """
        # ä¸ºæ¯ä¸ªæ–‡æ¡£è®¡ç®— RRF åˆ†æ•°
        rrf_scores = defaultdict(float)
        doc_info = {}  # å­˜å‚¨æ–‡æ¡£ä¿¡æ¯
        
        # BM25 ç»“æœ
        for rank, result in enumerate(bm25_results, start=1):
            doc_key = result["text"][:100]  # ä½¿ç”¨å‰100å­—ç¬¦ä½œä¸ºå”¯ä¸€æ ‡è¯†
            rrf_scores[doc_key] += self.bm25_weight / (k + rank)
            if doc_key not in doc_info:
                doc_info[doc_key] = result
        
        # å‘é‡æ£€ç´¢ç»“æœ
        for rank, result in enumerate(vector_results, start=1):
            doc_key = result["text"][:100]
            rrf_scores[doc_key] += self.vector_weight / (k + rank)
            if doc_key not in doc_info:
                doc_info[doc_key] = result
        
        # æŒ‰ RRF åˆ†æ•°æ’åº
        sorted_docs = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_results = []
        for doc_key, rrf_score in sorted_docs:
            result = doc_info[doc_key].copy()
            result["rrf_score"] = float(rrf_score)
            result["fusion_method"] = "RRF"
            final_results.append(result)
        
        return final_results
    
    def hybrid_retrieve(
        self,
        query: str,
        db_name: str,
        k: int = 5
    ) -> List[Dict[str, Any]]:
        """æ··åˆæ£€ç´¢ï¼ˆå•ä¸ªåº“ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            db_name: æ•°æ®åº“åç§°
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            èåˆåçš„æ£€ç´¢ç»“æœ
        """
        # 1. BM25 æ£€ç´¢
        bm25_results = self._bm25_search(query, db_name, k=k*2)
        
        # 2. å‘é‡æ£€ç´¢
        vector_results = self._vector_search(query, db_name, k=k*2)
        
        # 3. èåˆæ’åº
        fused_results = self._reciprocal_rank_fusion(bm25_results, vector_results)
        
        self._logger.debug(
            f"ğŸ”„ æ··åˆæ£€ç´¢ {db_name}: BM25={len(bm25_results)}, "
            f"Vector={len(vector_results)}, Fused={len(fused_results)}"
        )
        
        return fused_results[:k]
    
    def retrieve(
        self,
        query: str,
        *,
        filters: dict[str, Any] | None = None,
        k: int = 4,
    ) -> list[dict[str, Any]]:
        """å¤šåº“æ··åˆæ£€ç´¢æ¥å£ï¼ˆå…¼å®¹åŸæœ‰æ¥å£ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            filters: è¿‡æ»¤æ¡ä»¶ï¼ˆæ”¯æŒ db_name å‚æ•°æŒ‡å®šå•ä¸€æ•°æ®åº“ï¼‰
            k: æ¯ä¸ªåº“è¿”å›çš„ç»“æœæ•°é‡
            
        Returns:
            ç»Ÿä¸€æ ¼å¼çš„æ£€ç´¢ç»“æœ
        """
        filters = filters or {}
        patient_id = filters.get("patient_id")
        db_name = filters.get("db_name")  # å¦‚æœæŒ‡å®šäº†db_nameï¼ŒåªæŸ¥è¯¢è¯¥æ•°æ®åº“
        
        all_results = []
        
        # å¦‚æœæŒ‡å®šäº†å•ä¸€æ•°æ®åº“ï¼ŒåªæŸ¥è¯¢è¯¥åº“
        if db_name:
            source_map = {
                "HospitalProcess_db": "HospitalProcess",
                "MedicalGuide_db": "MedicalGuide",
                "ClinicalCase_db": "ClinicalCase",
                "HighQualityQA_db": "HighQualityQA",
                "UserHistory_db": "UserHistory",
            }
            results = self.hybrid_retrieve(query, db_name, k=k)
            for r in results:
                r["meta"]["source"] = source_map.get(db_name, db_name)
                if patient_id and db_name == "UserHistory_db":
                    r["meta"]["patient_id"] = patient_id
            return self._format_results(results, k)
        
        # å¦åˆ™æŒ‰ç…§åŸæœ‰é€»è¾‘æŸ¥è¯¢å¤šä¸ªåº“
        
        # 1. æ‚£è€…å†å²è®°å¿†ï¼ˆå¦‚æœæœ‰ patient_idï¼‰
        if patient_id:
            history_results = self.hybrid_retrieve(query, "UserHistory_db", k=2)
            for r in history_results:
                r["meta"]["patient_id"] = patient_id
                r["meta"]["source"] = "UserHistory"
            all_results.extend(history_results)
        
        # 2. é«˜è´¨é‡é—®ç­”åº“ï¼ˆæ ¸å¿ƒï¼‰
        qa_results = self.hybrid_retrieve(query, "HighQualityQA_db", k=k)
        for r in qa_results:
            r["meta"]["source"] = "HighQualityQA"
        all_results.extend(qa_results)
        
        # 3. åŒ»å­¦æŒ‡å—åº“ï¼ˆåŒ»å­¦ä¸“ä¸šçŸ¥è¯†ï¼‰
        guide_results = self.hybrid_retrieve(query, "MedicalGuide_db", k=k)
        for r in guide_results:
            r["meta"]["source"] = "MedicalGuide"
        all_results.extend(guide_results)
        
        # 4. åŒ»é™¢æµç¨‹åº“ï¼ˆåŒ»é™¢é€šç”¨æµç¨‹ã€æ¨¡æ¿ç­‰ï¼‰
        # ä»…åœ¨æŸ¥è¯¢åŒ…å«æµç¨‹ç›¸å…³å…³é”®è¯æ—¶æ£€ç´¢
        if any(kw in query for kw in ["æµç¨‹", "æ¨¡æ¿", "è¯æ˜", "ç—…å‡", "ç—…å†", "è¡¨å•", "SOP", "ç¼´è´¹", "é¢„çº¦", "æŒ‚å·"]):
            process_results = self.hybrid_retrieve(query, "HospitalProcess_db", k=k)
            for r in process_results:
                r["meta"]["source"] = "HospitalProcess"
            all_results.extend(process_results)
        
        # 5. ä¸´åºŠæ¡ˆä¾‹åº“ï¼ˆå¯é€‰ï¼‰
        # case_results = self.hybrid_retrieve(query, "ClinicalCase_db", k=k)
        # for r in case_results:
        #     r["meta"]["source"] = "ClinicalCase"
        # all_results.extend(case_results)
        
        # å»é‡å¹¶æ ¼å¼åŒ–
        return self._format_results(all_results, k * 2)
    
    def _format_results(
        self,
        results: List[Dict[str, Any]],
        max_results: int
    ) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–å¹¶å»é‡ç»“æœ"""
        seen = set()
        formatted = []
        
        for r in results:
            # å»é‡é”®
            key = r.get("text", "")[:50]
            if key in seen:
                continue
            seen.add(key)
            
            # ç»Ÿä¸€æ ¼å¼
            formatted.append({
                "doc_id": r["meta"].get("source", "unknown"),
                "chunk_id": r["meta"].get("chunk_id", "0"),
                "score": r.get("rrf_score", r.get("score", 0)),
                "text": r["text"],
                "meta": {
                    **r["meta"],
                    "retrieval_method": r.get("fusion_method", r.get("source", "unknown"))
                }
            })
        
        # æŒ‰åˆ†æ•°æ’åº
        formatted.sort(key=lambda x: x["score"], reverse=True)
        return formatted[:max_results]


__all__ = ["HybridRetriever"]
