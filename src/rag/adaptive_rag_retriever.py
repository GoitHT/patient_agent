"""Adaptive RAG æ£€ç´¢å™¨ - å®Œå…¨æ›¿æ¢åŸæœ‰ RAG ç³»ç»Ÿ
æ•´åˆ SPLLM-RAG1 çš„å¤šå‘é‡åº“æ£€ç´¢ã€Adaptive RAG æµç¨‹
"""
from __future__ import annotations

import os
import sys
from pathlib import Path
from typing import Any
import logging

# å¼ºåˆ¶ä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆåœ¨å¯¼å…¥ HuggingFace åº“ä¹‹å‰è®¾ç½®ï¼‰
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'

# ç¦ç”¨ä¸å¿…è¦çš„è­¦å‘Š
logging.getLogger("chromadb").setLevel(logging.ERROR)


class AdaptiveRAGRetriever:
    """Adaptive RAG æ£€ç´¢å™¨ - æ¥å£é€‚é…å™¨
    
    æœ¬ç±»å®ç°ä¸ ChromaRetriever ç›¸åŒçš„æ¥å£ï¼Œä½†åº•å±‚ä½¿ç”¨ï¼š
    1. çœŸå®è¯­ä¹‰åµŒå…¥ï¼ˆtext2vec-base-chineseï¼‰
    2. å¤šå‘é‡åº“æ£€ç´¢ï¼ˆåŒ»å­¦æŒ‡å—ã€ä¸´åºŠæ¡ˆä¾‹ã€é«˜è´¨é‡é—®ç­”ã€ç”¨æˆ·å†å²ï¼‰
    3. ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…
    
    ç‰¹æ€§ï¼š
        - å…¼å®¹åŸæœ‰ retrieve() æ¥å£
        - æ”¯æŒæ‚£è€…å†å²è®°å¿†æ£€ç´¢
        - æ”¯æŒé«˜è´¨é‡é—®ç­”å‚è€ƒ
        - æ”¯æŒåŒ»å­¦æŒ‡å—å’Œä¸´åºŠæ¡ˆä¾‹æ£€ç´¢
    """
    
    def __init__(
        self,
        *,
        spllm_root: Path | str,
        cache_folder: Path | str | None = None,
        cosine_threshold: float = 0.3,
        embed_model: str = "shibing624/text2vec-base-chinese",
    ):
        """
        Args:
            spllm_root: SPLLM-RAG1 é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« chroma/ æ–‡ä»¶å¤¹ï¼‰
            cache_folder: æ¨¡å‹ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤ä¸º spllm_root/model_cacheï¼‰
            cosine_threshold: ä½™å¼¦è·ç¦»é˜ˆå€¼ï¼ˆ0-1ï¼Œè¶Šå°è¶Šä¸¥æ ¼ï¼‰
            embed_model: åµŒå…¥æ¨¡å‹åç§°
        """
        self.spllm_root = Path(spllm_root).resolve()
        self.cache_folder = Path(cache_folder) if cache_folder else self.spllm_root / "model_cache"
        self.cosine_threshold = cosine_threshold
        self.embed_model = embed_model
        
        # è®¾ç½®ç¼“å­˜è·¯å¾„
        os.environ['HF_HOME'] = str(self.cache_folder)
        
        # å»¶è¿Ÿå¯¼å…¥ï¼ˆé¿å…å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼‰
        self._embeddings = None
        self._dbs = {}
        
        # æ—¥å¿—
        self._logger = logging.getLogger("hospital_agent.adaptive_rag")
        self._logger.info(f"ğŸ“¦ AdaptiveRAG åˆå§‹åŒ–: spllm_root={self.spllm_root}")
    
    def _init_embeddings(self):
        """å»¶è¿Ÿåˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆé¦–æ¬¡è°ƒç”¨ retrieve æ—¶è§¦å‘ï¼‰"""
        if self._embeddings is not None:
            return
        
        try:
            from langchain_huggingface import HuggingFaceEmbeddings
            
            self._embeddings = HuggingFaceEmbeddings(
                model_name=self.embed_model,
                model_kwargs={"device": "cpu"},
                encode_kwargs={
                    "normalize_embeddings": True,
                    "batch_size": 32
                },
                cache_folder=str(self.cache_folder)
            )
            
            # æµ‹è¯•åµŒå…¥
            test_vec = self._embeddings.embed_query("æµ‹è¯•")
            self._logger.info(f"âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆç»´åº¦={len(test_vec)}ï¼‰")
        except Exception as e:
            self._logger.error(f"âŒ åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {e}")
    
    def _get_db(self, db_name: str):
        """è·å–æˆ–åŠ è½½å‘é‡åº“ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if db_name in self._dbs:
            return self._dbs[db_name]
        
        self._init_embeddings()
        
        try:
            from langchain_chroma import Chroma
            
            db_path = self.spllm_root / "chroma" / db_name
            if not db_path.exists():
                self._logger.warning(f"âš ï¸  å‘é‡åº“è·¯å¾„ä¸å­˜åœ¨: {db_path}")
                return None
            
            db = Chroma(
                persist_directory=str(db_path),
                embedding_function=self._embeddings,
                collection_metadata={"hnsw:space": "cosine"}
            )
            self._dbs[db_name] = db
            self._logger.debug(f"âœ… å‘é‡åº“åŠ è½½æˆåŠŸ: {db_name}")
            return db
        except Exception as e:
            self._logger.error(f"âŒ å‘é‡åº“ {db_name} åŠ è½½å¤±è´¥: {e}")
            return None
    
    def retrieve(
        self,
        query: str,
        *,
        filters: dict[str, Any] | None = None,
        k: int = 4,
    ) -> list[dict[str, Any]]:
        """æ£€ç´¢æ¥å£ï¼ˆå…¼å®¹ ChromaRetrieverï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            filters: è¿‡æ»¤æ¡ä»¶ï¼ˆå¯é€‰ï¼ŒåŒ…å« dept/type/patient_idï¼‰
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            ç»Ÿä¸€æ ¼å¼çš„æ£€ç´¢ç»“æœ: [{doc_id, chunk_id, score, text, meta}, ...]
        """
        patient_id = filters.get("patient_id") if filters else None
        dept = filters.get("dept") if filters else None
        
        results = []
        
        # 1. æ‚£è€…å†å²è®°å¿†ï¼ˆå¦‚æœæœ‰ patient_idï¼‰
        if patient_id:
            history_results = self._retrieve_history(query, patient_id, k=2)
            results.extend(history_results)
        
        # 2. é«˜è´¨é‡é—®ç­”åº“ï¼ˆæ ¸å¿ƒï¼‰
        qa_results = self._retrieve_high_quality_qa(query, k=k)
        results.extend(qa_results)
        
        # 3. åŒ»å­¦æŒ‡å—åº“ï¼ˆè¡¥å……ä¸“ä¸šçŸ¥è¯†ï¼‰
        guide_results = self._retrieve_guide(query, k=k)
        results.extend(guide_results)
        
        # 4. ä¸´åºŠæ¡ˆä¾‹åº“ï¼ˆå¯é€‰ï¼ŒæŒ‰éœ€å¯ç”¨ï¼‰
        # case_results = self._retrieve_case(query, k=k)
        # results.extend(case_results)
        
        # å»é‡å¹¶æŒ‰åˆ†æ•°æ’åº
        unique_results = self._deduplicate_and_sort(results)
        
        # é™åˆ¶è¿”å›æ•°é‡
        return unique_results[:k * 2]  # è¿”å›æœ€å¤š 2k ä¸ªç»“æœ
    
    def _retrieve_history(
        self,
        query: str,
        patient_id: str,
        k: int = 2
    ) -> list[dict[str, Any]]:
        """æ£€ç´¢æ‚£è€…å†å²è®°å¿†"""
        db = self._get_db("UserHistory_db")
        if not db:
            return []
        
        try:
            # similarity_search_with_score è¿”å› (doc, distance)
            docs_and_distances = db.similarity_search_with_score(
                query,
                k=k,
                filter={"patient_id": patient_id}
            )
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold:
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": f"history_{patient_id}",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "UserHistory",
                            "patient_id": patient_id,
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ“œ å†å²è®°å¿†æ£€ç´¢: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  å†å²è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_high_quality_qa(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢é«˜è´¨é‡é—®ç­”ï¼ˆæ ¸å¿ƒçŸ¥è¯†åº“ï¼‰"""
        db = self._get_db("HighQualityQA_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold:
                    similarity = max(0, 1 - distance)
                    question = doc.metadata.get("question", "")
                    answer = doc.metadata.get("answer", "")
                    
                    # æ ¼å¼åŒ–ä¸ºé—®ç­”å¯¹
                    text = f"ã€å†å²é—®ç­”ã€‘\né—®ï¼š{question}\nç­”ï¼š{answer[:300]}..."
                    
                    results.append({
                        "doc_id": "high_quality_qa",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": text,
                        "meta": {
                            "source": "HighQualityQA",
                            "question": question,
                            "answer": answer,
                            "distance": distance,
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ’ é«˜è´¨é‡é—®ç­”: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  é«˜è´¨é‡é—®ç­”æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_guide(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢åŒ»å­¦æŒ‡å—"""
        db = self._get_db("MedicalGuide_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold * 1.5:  # æŒ‡å—åº“é˜ˆå€¼æ”¾å®½ä¸€äº›
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": "medical_guide",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "MedicalGuide",
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ“š åŒ»å­¦æŒ‡å—: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  åŒ»å­¦æŒ‡å—æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_case(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢ä¸´åºŠæ¡ˆä¾‹"""
        db = self._get_db("ClinicalCase_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold * 1.2:
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": "clinical_case",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "ClinicalCase",
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ¥ ä¸´åºŠæ¡ˆä¾‹: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  ä¸´åºŠæ¡ˆä¾‹æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _deduplicate_and_sort(self, results: list[dict[str, Any]]) -> list[dict[str, Any]]:
        """å»é‡å¹¶æŒ‰åˆ†æ•°æ’åº"""
        seen = set()
        unique = []
        
        for r in results:
            # ä½¿ç”¨æ–‡æœ¬å‰50ä¸ªå­—ç¬¦ä½œä¸ºå»é‡é”®
            key = (r.get("doc_id"), r.get("text", "")[:50])
            if key not in seen:
                seen.add(key)
                unique.append(r)
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        unique.sort(key=lambda x: x.get("score", 0), reverse=True)
        return unique


__all__ = ["AdaptiveRAGRetriever"]
