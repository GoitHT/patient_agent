"""Adaptive RAG æ£€ç´¢å™¨ - å®Œå…¨æ›¿æ¢åŸæœ‰ RAG ç³»ç»Ÿ
æ•´åˆ SPLLM-RAG1 çš„å¤šå‘é‡åº“æ£€ç´¢ã€Adaptive RAG æµç¨‹
"""
from __future__ import annotations

import os
import sys
from pathlib import Path
from typing import Any
import logging

# å¼ºåˆ¶ä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆåœ¨å¯¼å…¥ HuggingFace åº“ä¹‹å‰è®¾ç½®ï¼‰
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'

# ç¦ç”¨ä¸å¿…è¦çš„è­¦å‘Š
logging.getLogger("chromadb").setLevel(logging.ERROR)


class AdaptiveRAGRetriever:
    """Adaptive RAG æ£€ç´¢å™¨ - æ¥å£é€‚é…å™¨
    
    æœ¬ç±»å®ç°ä¸ ChromaRetriever ç›¸åŒçš„æ¥å£ï¼Œä½†åº•å±‚ä½¿ç”¨ï¼š
    1. çœŸå®è¯­ä¹‰åµŒå…¥ï¼ˆtext2vec-base-chineseï¼‰
    2. å¤šå‘é‡åº“æ£€ç´¢ï¼ˆåŒ»å­¦æŒ‡å—ã€ä¸´åºŠæ¡ˆä¾‹ã€é«˜è´¨é‡é—®ç­”ã€ç”¨æˆ·å†å²ï¼‰
    3. ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…
    
    ç‰¹æ€§ï¼š
        - å…¼å®¹åŸæœ‰ retrieve() æ¥å£
        - æ”¯æŒæ‚£è€…å†å²è®°å¿†æ£€ç´¢
        - æ”¯æŒé«˜è´¨é‡é—®ç­”å‚è€ƒ
        - æ”¯æŒåŒ»å­¦æŒ‡å—å’Œä¸´åºŠæ¡ˆä¾‹æ£€ç´¢
    """
    
    def __init__(
        self,
        *,
        spllm_root: Path | str,
        cache_folder: Path | str | None = None,
        cosine_threshold: float = 0.3,
        embed_model: str = "BAAI/bge-large-zh-v1.5",
    ):
        """
        Args:
            spllm_root: SPLLM-RAG1 é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« chroma/ æ–‡ä»¶å¤¹ï¼‰
            cache_folder: æ¨¡å‹ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤ä¸º spllm_root/model_cacheï¼‰
            cosine_threshold: ä½™å¼¦è·ç¦»é˜ˆå€¼ï¼ˆ0-1ï¼Œè¶Šå°è¶Šä¸¥æ ¼ï¼‰
            embed_model: åµŒå…¥æ¨¡å‹åç§°
        """
        self.spllm_root = Path(spllm_root).resolve()
        self.cache_folder = Path(cache_folder) if cache_folder else self.spllm_root / "model_cache"
        self.cosine_threshold = cosine_threshold
        self.embed_model = embed_model
        
        # è®¾ç½®ç¼“å­˜è·¯å¾„
        os.environ['HF_HOME'] = str(self.cache_folder)
        
        # å»¶è¿Ÿå¯¼å…¥ï¼ˆé¿å…å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼‰
        self._embeddings = None
        self._dbs = {}
        
        # æ—¥å¿—
        self._logger = logging.getLogger("hospital_agent.adaptive_rag")
        self._logger.info(f"ğŸ“¦ AdaptiveRAG åˆå§‹åŒ–: spllm_root={self.spllm_root}")
    
    def _init_embeddings(self):
        """å»¶è¿Ÿåˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆé¦–æ¬¡è°ƒç”¨ retrieve æ—¶è§¦å‘ï¼‰"""
        if self._embeddings is not None:
            return
        
        try:
            # ä¸´æ—¶å±è”½åµŒå…¥æ¨¡å‹çš„åŠ è½½æ—¥å¿—
            import logging as std_logging
            sentence_transformers_logger = std_logging.getLogger('sentence_transformers')
            transformers_logger = std_logging.getLogger('transformers')
            old_st_level = sentence_transformers_logger.level
            old_tf_level = transformers_logger.level
            sentence_transformers_logger.setLevel(std_logging.WARNING)
            transformers_logger.setLevel(std_logging.WARNING)
            
            from langchain_huggingface import HuggingFaceEmbeddings
            
            self._embeddings = HuggingFaceEmbeddings(
                model_name=self.embed_model,
                model_kwargs={"device": "cpu"},
                encode_kwargs={
                    "normalize_embeddings": True,
                    "batch_size": 32
                },
                cache_folder=str(self.cache_folder)
            )
            
            # æ¢å¤æ—¥å¿—çº§åˆ«
            sentence_transformers_logger.setLevel(old_st_level)
            transformers_logger.setLevel(old_tf_level)
            
            # æµ‹è¯•åµŒå…¥
            test_vec = self._embeddings.embed_query("æµ‹è¯•")
            self._logger.info(f"âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆç»´åº¦={len(test_vec)}ï¼‰")
        except Exception as e:
            # æ¢å¤æ—¥å¿—çº§åˆ«ï¼ˆå³ä½¿å‡ºé”™ï¼‰
            try:
                sentence_transformers_logger.setLevel(old_st_level)
                transformers_logger.setLevel(old_tf_level)
            except:
                pass
            self._logger.error(f"âŒ åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {e}")
    
    def _get_db(self, db_name: str):
        """è·å–æˆ–åŠ è½½å‘é‡åº“ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if db_name in self._dbs:
            return self._dbs[db_name]
        
        self._init_embeddings()
        
        try:
            from langchain_chroma import Chroma
            
            db_path = self.spllm_root / "chroma" / db_name
            if not db_path.exists():
                self._logger.warning(f"âš ï¸  å‘é‡åº“è·¯å¾„ä¸å­˜åœ¨: {db_path}")
                return None
            
            db = Chroma(
                persist_directory=str(db_path),
                embedding_function=self._embeddings,
                collection_metadata={"hnsw:space": "cosine"}
            )
            self._dbs[db_name] = db
            self._logger.debug(f"âœ… å‘é‡åº“åŠ è½½æˆåŠŸ: {db_name}")
            return db
        except Exception as e:
            self._logger.error(f"âŒ å‘é‡åº“ {db_name} åŠ è½½å¤±è´¥: {e}")
            return None
    
    def retrieve(
        self,
        query: str,
        *,
        filters: dict[str, Any] | None = None,
        k: int = 4,
    ) -> list[dict[str, Any]]:
        """æ£€ç´¢æ¥å£ï¼ˆå…¼å®¹ ChromaRetrieverï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            filters: è¿‡æ»¤æ¡ä»¶ï¼ˆå¯é€‰ï¼ŒåŒ…å« dept/type/patient_id/scenario/db_nameï¼‰
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            ç»Ÿä¸€æ ¼å¼çš„æ£€ç´¢ç»“æœ: [{doc_id, chunk_id, score, text, meta}, ...]
        """
        filters = filters or {}
        patient_id = filters.get("patient_id")
        dept = filters.get("dept")
        scenario = filters.get("scenario")
        db_name = filters.get("db_name")  # å¦‚æœæŒ‡å®šäº†db_nameï¼ŒåªæŸ¥è¯¢è¯¥æ•°æ®åº“
        
        results = []
        
        # ã€ä¼˜å…ˆç­–ç•¥ã€‘å¦‚æœæŒ‡å®šäº† db_nameï¼Œå¼ºåˆ¶åªæŸ¥è¯¢è¯¥å•ä¸€æ•°æ®åº“
        if db_name:
            db_method_map = {
                "HospitalProcess_db": self._retrieve_hospital_process,
                "MedicalGuide_db": self._retrieve_guide,
                "ClinicalCase_db": self._retrieve_case,
                "HighQualityQA_db": self._retrieve_high_quality_qa,
                "UserHistory_db": lambda q, k: self._retrieve_history(q, patient_id, k) if patient_id else [],
            }
            method = db_method_map.get(db_name)
            if method:
                results = method(query, k=k)
            else:
                self._logger.warning(f"âš ï¸  æœªçŸ¥çš„æ•°æ®åº“åç§°: {db_name}")
            return results[:k]  # å¼ºåˆ¶è¿”å›ï¼Œä¸èµ°åç»­é€»è¾‘
        
        # æ ¹æ®åœºæ™¯é€‰æ‹©æ£€ç´¢ç­–ç•¥
        if scenario == "patient_history":
            # ä¸“æ³¨äºæ‚£è€…å†å²ï¼ˆC5/C8/C14ï¼‰
            if patient_id:
                history_results = self._retrieve_history(query, patient_id, k=k)
                results.extend(history_results)
            guide_results = self._retrieve_guide(query, k=k//2)
            results.extend(guide_results)
        
        elif scenario == "clinical_case":
            # ä¸“æ³¨äºä¸´åºŠæ¡ˆä¾‹ï¼ˆC11/C12ï¼‰- åªæŸ¥è¯¢ä¸´åºŠæ¡ˆä¾‹åº“
            case_results = self._retrieve_case(query, k=k)
            results.extend(case_results)
        
        elif scenario == "quality_qa":
            # ä¸“æ³¨äºé«˜è´¨é‡é—®ç­”ï¼ˆS4ï¼‰- åªæŸ¥è¯¢é«˜è´¨é‡é—®ç­”åº“
            qa_results = self._retrieve_high_quality_qa(query, k=k)
            results.extend(qa_results)
        
        elif scenario == "hospital_process":
            # ä¸“æ³¨äºè§„åˆ™æµç¨‹åº“ï¼ˆC5/C8/C14/C15ï¼‰- åªæŸ¥è¯¢æµç¨‹è§„åˆ™åº“
            process_results = self._retrieve_hospital_process(query, k=k)
            results.extend(process_results)
        
        else:
            # é»˜è®¤ç­–ç•¥ï¼šå‡è¡¡æ£€ç´¢æ‰€æœ‰åº“
            # 1. æ‚£è€…å†å²è®°å¿†ï¼ˆå¦‚æœæœ‰ patient_idï¼‰
            if patient_id:
                history_results = self._retrieve_history(query, patient_id, k=2)
                results.extend(history_results)
            
            # 2. é«˜è´¨é‡é—®ç­”åº“ï¼ˆæ ¸å¿ƒï¼‰
            qa_results = self._retrieve_high_quality_qa(query, k=k)
            results.extend(qa_results)
            
            # 3. åŒ»å­¦æŒ‡å—åº“ï¼ˆè¡¥å……ä¸“ä¸šçŸ¥è¯†ï¼‰
            guide_results = self._retrieve_guide(query, k=k)
            results.extend(guide_results)
            
            # 4. ä¸´åºŠæ¡ˆä¾‹åº“ï¼ˆå·²å¯ç”¨ï¼‰
            case_results = self._retrieve_case(query, k=k//2)
            results.extend(case_results)
            results.extend(case_results)
        
        # å»é‡å¹¶æŒ‰åˆ†æ•°æ’åº
        unique_results = self._deduplicate_and_sort(results)
        
        # é™åˆ¶è¿”å›æ•°é‡
        return unique_results[:k * 2]  # è¿”å›æœ€å¤š 2k ä¸ªç»“æœ
    
    def _retrieve_history(
        self,
        query: str,
        patient_id: str,
        k: int = 2
    ) -> list[dict[str, Any]]:
        """æ£€ç´¢æ‚£è€…å†å²è®°å¿†"""
        db = self._get_db("UserHistory_db")
        if not db:
            return []
        
        try:
            # similarity_search_with_score è¿”å› (doc, distance)
            docs_and_distances = db.similarity_search_with_score(
                query,
                k=k,
                filter={"patient_id": patient_id}
            )
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold:
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": f"history_{patient_id}",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "UserHistory",
                            "patient_id": patient_id,
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ“œ å†å²è®°å¿†æ£€ç´¢: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  å†å²è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def retrieve_patient_test_history(
        self,
        patient_id: str,
        test_keywords: list[str],
        k: int = 5
    ) -> list[dict[str, Any]]:
        """æ£€ç´¢æ‚£è€…å†å²æ£€æŸ¥è®°å½•ï¼ˆç”¨äºé¿å…é‡å¤å¼€å•ï¼‰
        
        Args:
            patient_id: æ‚£è€…ID
            test_keywords: æ£€æŸ¥å…³é”®è¯åˆ—è¡¨ï¼ˆå¦‚ ["CT", "MRI", "è¡€å¸¸è§„"]ï¼‰
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ‚£è€…å†å²æ£€æŸ¥è®°å½•åˆ—è¡¨
        """
        if not patient_id or not test_keywords:
            return []
        
        # æ„å»ºæŸ¥è¯¢è¯­å¥
        query = f"æ£€æŸ¥ æ£€éªŒ å¼€å• {' '.join(test_keywords)}"
        
        db = self._get_db("UserHistory_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(
                query,
                k=k,
                filter={"patient_id": patient_id}
            )
            
            results = []
            for doc, distance in docs_and_distances:
                # å†å²æ£€æŸ¥è®°å½•é˜ˆå€¼æ”¾å®½
                if distance < self.cosine_threshold * 1.5:
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": f"test_history_{patient_id}",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "UserHistory",
                            "patient_id": patient_id,
                            "keywords": test_keywords,
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.info(f"ğŸ” å†å²æ£€æŸ¥è®°å½•: æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å½•")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  å†å²æ£€æŸ¥è®°å½•æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_high_quality_qa(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢é«˜è´¨é‡é—®ç­”ï¼ˆæ ¸å¿ƒçŸ¥è¯†åº“ï¼‰"""
        db = self._get_db("HighQualityQA_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold:
                    similarity = max(0, 1 - distance)
                    question = doc.metadata.get("question", "")
                    answer = doc.metadata.get("answer", "")
                    
                    # æ ¼å¼åŒ–ä¸ºé—®ç­”å¯¹
                    text = f"ã€å†å²é—®ç­”ã€‘\né—®ï¼š{question}\nç­”ï¼š{answer[:300]}..."
                    
                    results.append({
                        "doc_id": "high_quality_qa",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": text,
                        "meta": {
                            "source": "HighQualityQA",
                            "question": question,
                            "answer": answer,
                            "distance": distance,
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ’ é«˜è´¨é‡é—®ç­”: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  é«˜è´¨é‡é—®ç­”æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_guide(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢åŒ»å­¦æŒ‡å—"""
        db = self._get_db("MedicalGuide_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold * 1.5:  # æŒ‡å—åº“é˜ˆå€¼æ”¾å®½ä¸€äº›
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": "medical_guide",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "MedicalGuide",
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ“š åŒ»å­¦æŒ‡å—: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  åŒ»å­¦æŒ‡å—æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_case(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢ä¸´åºŠæ¡ˆä¾‹"""
        db = self._get_db("ClinicalCase_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                if distance < self.cosine_threshold * 1.2:
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": "clinical_case",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "ClinicalCase",
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ¥ ä¸´åºŠæ¡ˆä¾‹: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  ä¸´åºŠæ¡ˆä¾‹æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _retrieve_hospital_process(self, query: str, k: int = 3) -> list[dict[str, Any]]:
        """æ£€ç´¢åŒ»é™¢è§„åˆ™æµç¨‹ï¼ˆSOPã€æ–‡ä¹¦æ¨¡æ¿ã€å®£æ•™ææ–™ç­‰ï¼‰
        
        ç”¨äºï¼š
        - C5: é€šç”¨å°±è¯Šæµç¨‹SOP
        - C8: æ£€æŸ¥/æ£€éªŒå‰å‡†å¤‡äº‹é¡¹
        - C14: é—¨è¯Šç—…å†/è¯Šæ–­è¯æ˜/ç—…å‡æ¡æ¨¡æ¿
        - C15: ç–¾ç—…ç§‘æ™®ææ–™ã€å¥åº·å®£æ•™å’Œéšè®¿è®¡åˆ’æ¨¡æ¿
        """
        db = self._get_db("HospitalProcess_db")
        if not db:
            return []
        
        try:
            docs_and_distances = db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, distance in docs_and_distances:
                # è§„åˆ™æµç¨‹åº“è¦æ±‚ç²¾å‡†åŒ¹é…
                if distance < self.cosine_threshold:
                    similarity = max(0, 1 - distance)
                    results.append({
                        "doc_id": "hospital_process",
                        "chunk_id": doc.metadata.get("chunk_id", "0"),
                        "score": float(similarity),
                        "text": doc.page_content,
                        "meta": {
                            "source": "HospitalProcess",
                            **doc.metadata
                        }
                    })
            
            if results:
                self._logger.debug(f"ğŸ“‹ è§„åˆ™æµç¨‹: æ‰¾åˆ° {len(results)} æ¡")
            return results
        except Exception as e:
            self._logger.warning(f"âš ï¸  è§„åˆ™æµç¨‹æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _deduplicate_and_sort(self, results: list[dict[str, Any]]) -> list[dict[str, Any]]:
        """å»é‡å¹¶æŒ‰åˆ†æ•°æ’åº"""
        seen = set()
        unique = []
        
        for r in results:
            # ä½¿ç”¨æ–‡æœ¬å‰50ä¸ªå­—ç¬¦ä½œä¸ºå»é‡é”®
            key = (r.get("doc_id"), r.get("text", "")[:50])
            if key not in seen:
                seen.add(key)
                unique.append(r)
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        unique.sort(key=lambda x: x.get("score", 0), reverse=True)
        return unique


__all__ = ["AdaptiveRAGRetriever"]
